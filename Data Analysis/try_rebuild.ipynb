{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "72af16d9fbbb86b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleanup bewegungen.csv -> adjust dtype and load to parquet for more efficient access\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "\n",
    "# Adjusted dtype mapping\n",
    "df_bewegungen = pd.read_csv(\n",
    "    '../Data/bewegungen.csv',\n",
    "    dtype={\n",
    "        \"MOVNUM\": \"int64\",\n",
    "        \"WORNUM\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"MOVTYP\": \"category\",\n",
    "        \"MOVKEY\": \"category\",\n",
    "        \"SRC_ITEM\": \"category\", #category ideal - unique 900k articles, repeated articles IDs, column might be used for grouping, filtering and comparisons later on\n",
    "        \"SRC_LOT\": \"category\",\n",
    "        \"SRC_QACODE\": \"category\",\n",
    "        \"DST_LOT\": \"category\",\n",
    "        \"DST_QACODE\": \"category\",\n",
    "        \"SRC_WA\": \"category\",\n",
    "        \"DST_WA\": \"category\",\n",
    "        \"SRC_X\": \"object\",\n",
    "        \"SRC_Y\": \"object\",\n",
    "        \"SRC_Z\": \"category\",\n",
    "        \"DST_X\": \"object\", #always the same destination for X,Y and Z -> Warenausgang\n",
    "        \"DST_Y\": \"object\",\n",
    "        \"DST_Z\": \"category\",\n",
    "        \"REQQTY\": \"int64\",\n",
    "        \"CONQTY\": \"int64\",\n",
    "        \"INCNUM\": \"int64\",\n",
    "        \"LISNUM\": \"int64\",\n",
    "        \"USERID\": \"category\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"],\n",
    "    chunksize=100000  # Process large files in chunks\n",
    ")\n",
    "\n",
    "# Process chunks\n",
    "for chunk in df_bewegungen:\n",
    "    print(chunk.info())\n",
    "\n",
    "# Save to Parquet\n",
    "df.to_parquet('../Data/processed_bewegungen.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../Data/bewegungen.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlow_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m         \u001B[49m\u001B[38;5;66;43;03m# Prevent memory fragmentation\u001B[39;49;00m\n\u001B[1;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/HS24_Machine_Learning_ManuelRenold/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/HS24_Machine_Learning_ManuelRenold/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/HS24_Machine_Learning_ManuelRenold/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1919\u001B[0m     (\n\u001B[1;32m   1920\u001B[0m         index,\n\u001B[1;32m   1921\u001B[0m         columns,\n\u001B[1;32m   1922\u001B[0m         col_dict,\n\u001B[0;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/Documents/HS24_Machine_Learning_ManuelRenold/.venv/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:239\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 239\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_first_chunk:\n",
      "File \u001B[0;32mparsers.pyx:820\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:921\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:1083\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:1456\u001B[0m, in \u001B[0;36mpandas._libs.parsers._maybe_upcast\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Documents/HS24_Machine_Learning_ManuelRenold/.venv/lib/python3.12/site-packages/numpy/_core/multiarray.py:1153\u001B[0m, in \u001B[0;36mputmask\u001B[0;34m(a, mask, values)\u001B[0m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m \u001B[38;5;124;03m    copyto(dst, src, casting='same_kind', where=True)\u001B[39;00m\n\u001B[1;32m   1105\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1148\u001B[0m \n\u001B[1;32m   1149\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (dst, src, where)\n\u001B[0;32m-> 1153\u001B[0m \u001B[38;5;129m@array_function_from_c_func_and_dispatcher\u001B[39m(_multiarray_umath\u001B[38;5;241m.\u001B[39mputmask)\n\u001B[1;32m   1154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mputmask\u001B[39m(a, \u001B[38;5;241m/\u001B[39m, mask, values):\n\u001B[1;32m   1155\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1156\u001B[0m \u001B[38;5;124;03m    putmask(a, mask, values)\u001B[39;00m\n\u001B[1;32m   1157\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1194\u001B[0m \n\u001B[1;32m   1195\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (a, mask, values)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    '../Data/bewegungen.csv',\n",
    "    low_memory=False         # Prevent memory fragmentation\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-25T14:58:17.115299Z",
     "start_time": "2024-11-25T14:13:22.723838Z"
    }
   },
   "id": "576142b107d8d446",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in cleaned SRC_LOT: 131\n",
      "Cleaned unique values in SRC_LOT: [1 0 11 4 3 2 7 6 10 5 19 33 9 16 20 17 90 24 32 13 8 12 23 14 21 31 43 15\n",
      " 55 18 53 26 89 30 28 49 73 25 39 54 52 44 60 38 34 22 37 29 36 88 59 27\n",
      " 42 61 47 40 75 58 41 77 '000' '006' '001' '003' '002' '004' '008' '005'\n",
      " '007' '011' '009' '053' '052' '044' '014' '019' '013' '023' '032' '034'\n",
      " '012' '010' '031' '01' '022' '017' '089' '020' 'de001' '028' '021' '055'\n",
      " '016' '015' '024' 57 56 45 50 48 0.001 1001 74 46 '061' '033' '018' '054'\n",
      " '074' '043' '050' '039' '027' 'o001' '046' '030' '057' '036' '088' '049'\n",
      " '058' '025' '026' '029' 223 '090' '045' 91 62 35 51]\n"
     ]
    }
   ],
   "source": [
    "unique_values_count = df['SRC_LOT'].nunique()\n",
    "print(f\"Number of unique values in cleaned SRC_LOT: {unique_values_count}\")\n",
    "unique_values = df['SRC_LOT'].unique()\n",
    "print(f\"Cleaned unique values in SRC_LOT: {unique_values}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-25T14:08:13.871957Z",
     "start_time": "2024-11-25T14:08:13.110558Z"
    }
   },
   "id": "6980aebcb400a061",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c2/mxrc2sw14x12np58cyqcffpm0000gn/T/ipykernel_36298/1992164947.py:4: DtypeWarning: Columns (6,8,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../Data/bewegungen.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "      MOVNUM     WORNUM  STATUS MOVTYP MOVKEY  SRC_ITEM SRC_LOT SRC_QACODE  \\\n",
      "0  289678988  289678987      50    REL    PIC  36529803       1          H   \n",
      "1  289870562  289870561      50    REL    PIC  44118619       1          H   \n",
      "2  289833600  289833599      50    REL    PIC  13091411       1          H   \n",
      "3  289815260  289815259      50    REL    PIC   9636829       0          H   \n",
      "4  289839098  289839097      50    REL    PIC  16359571       1          H   \n",
      "\n",
      "  DST_LOT DST_QACODE  ...    RELNUM     LISNUM     SUMLIS     TRNNUM  \\\n",
      "0       1          H  ...  41484834  289679194  289679311  599324284   \n",
      "1       1          H  ...  41494178  289874022  289874463  599670338   \n",
      "2       1          H  ...  41492163  289835037  289835121  599596179   \n",
      "3       0          H  ...  41491410  289815703  289815805  599541258   \n",
      "4       1          H  ...  41492589  289840157  289725531  599576127   \n",
      "\n",
      "                CRTDAT               TRNDAT    USERID   VOLREQ     VOLPIC  \\\n",
      "0  2024-04-25 01:04:53  2024-04-25 08:16:39     24769  1795500  1795500.0   \n",
      "1  2024-04-25 17:34:53  2024-04-25 19:29:47    178141  1065600  1065600.0   \n",
      "2  2024-04-25 15:24:37  2024-04-25 16:42:37   LAESSIG   696672   696672.0   \n",
      "3  2024-04-25 14:34:37  2024-04-25 14:56:15  GUERBUEZ   299376   299376.0   \n",
      "4  2024-04-25 15:39:56  2024-04-25 16:03:15    104044  1706600  1706600.0   \n",
      "\n",
      "                      LOADDAT  \n",
      "0  2024-04-26 00:52:47.247838  \n",
      "1  2024-04-26 00:52:47.247838  \n",
      "2  2024-04-26 00:52:47.247838  \n",
      "3  2024-04-26 00:52:47.247838  \n",
      "4  2024-04-26 00:52:47.247838  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Cleaned DataFrame:\n",
      "      MOVNUM     WORNUM  STATUS MOVTYP MOVKEY  SRC_ITEM SRC_LOT SRC_QACODE  \\\n",
      "0  289678988  289678987      50    REL    PIC  36529803       1          H   \n",
      "1  289870562  289870561      50    REL    PIC  44118619       1          H   \n",
      "2  289833600  289833599      50    REL    PIC  13091411       1          H   \n",
      "3  289839098  289839097      50    REL    PIC  16359571       1          H   \n",
      "4  289807444  289807443      50    REL    PIC  38789620       1          H   \n",
      "\n",
      "  DST_LOT DST_QACODE  ...    RELNUM     LISNUM     SUMLIS     TRNNUM  \\\n",
      "0       1          H  ...  41484834  289679194  289679311  599324284   \n",
      "1       1          H  ...  41494178  289874022  289874463  599670338   \n",
      "2       1          H  ...  41492163  289835037  289835121  599596179   \n",
      "3       1          H  ...  41492589  289840157  289725531  599576127   \n",
      "4       1          H  ...  41491312  289808077  289726826  599529006   \n",
      "\n",
      "                CRTDAT               TRNDAT   USERID   VOLREQ     VOLPIC  \\\n",
      "0  2024-04-25 01:04:53  2024-04-25 08:16:39    24769  1795500  1795500.0   \n",
      "1  2024-04-25 17:34:53  2024-04-25 19:29:47   178141  1065600  1065600.0   \n",
      "2  2024-04-25 15:24:37  2024-04-25 16:42:37  LAESSIG   696672   696672.0   \n",
      "3  2024-04-25 15:39:56  2024-04-25 16:03:15   104044  1706600  1706600.0   \n",
      "4  2024-04-25 14:09:31  2024-04-25 14:44:06   170056  2825875  2825875.0   \n",
      "\n",
      "                      LOADDAT  \n",
      "0  2024-04-26 00:52:47.247838  \n",
      "1  2024-04-26 00:52:47.247838  \n",
      "2  2024-04-26 00:52:47.247838  \n",
      "3  2024-04-26 00:52:47.247838  \n",
      "4  2024-04-26 00:52:47.247838  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Cleaned data saved to: cleaned_file.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "\n",
    "\n",
    "# Display initial data\n",
    "print(f\"Initial DataFrame:\\n{df.head()}\")\n",
    "\n",
    "# Remove all float values from the column\n",
    "df = df[df['SRC_LOT'].apply(lambda x: not isinstance(x, float))]\n",
    "\n",
    "# Convert all entries in the column to strings\n",
    "df['SRC_LOT'] = df['SRC_LOT'].astype(str)\n",
    "\n",
    "# Strip leading zeros but ensure \"000\" becomes \"0\"\n",
    "df['SRC_LOT'] = df['SRC_LOT'].apply(lambda x: '0' if x == '000' else x.lstrip('0'))\n",
    "\n",
    "# Validate format (numeric only and max 3 characters)\n",
    "df['SRC_LOT'] = df['SRC_LOT'].apply(lambda x: x if x.isdigit() and len(x) <= 3 else None)\n",
    "\n",
    "# Filter out rows where SRC_LOT is None (invalid entries)\n",
    "df = df[df['SRC_LOT'].notna()]\n",
    "\n",
    "# Reset index after filtering\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print cleaned column\n",
    "unique_values_count = df['SRC_LOT'].nunique()\n",
    "print(f\"Number of unique values in cleaned SRC_LOT: {unique_values_count}\")\n",
    "unique_values = df['SRC_LOT'].unique()\n",
    "print(f\"Cleaned unique values in SRC_LOT: {unique_values}\")\n",
    "\n",
    "# Display cleaned data\n",
    "#print(f\"Cleaned DataFrame:\\n{df.head()}\")\n",
    "\n",
    "# Save the cleaned DataFrame back to a CSV file if needed\n",
    "#cleaned_file_path = 'cleaned_file.csv'\n",
    "#df.to_csv(cleaned_file_path, index=False)\n",
    "#print(f\"Cleaned data saved to: {cleaned_file_path}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-25T13:48:17.485134Z",
     "start_time": "2024-11-25T13:46:01.096850Z"
    }
   },
   "id": "256876afb0a01efa",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **show all COUNTED unique values per column**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b6ace03c930ed10"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: MOVNUM, Unique Values: 20094145\n",
      "Column: WORNUM, Unique Values: 20094145\n",
      "Column: STATUS, Unique Values: 3\n",
      "Column: MOVTYP, Unique Values: 1\n",
      "Column: MOVKEY, Unique Values: 1\n",
      "Column: SRC_ITEM, Unique Values: 914671\n",
      "Column: SRC_LOT, Unique Values: 131\n",
      "Column: SRC_QACODE, Unique Values: 4\n",
      "Column: DST_LOT, Unique Values: 131\n",
      "Column: DST_QACODE, Unique Values: 4\n",
      "Column: SRC_WA, Unique Values: 6\n",
      "Column: SRC_X, Unique Values: 1355\n",
      "Column: SRC_Y, Unique Values: 178\n",
      "Column: SRC_Z, Unique Values: 295\n",
      "Column: DST_WA, Unique Values: 1\n",
      "Column: DST_X, Unique Values: 1\n",
      "Column: DST_Y, Unique Values: 1\n",
      "Column: DST_Z, Unique Values: 1\n",
      "Column: REQQTY, Unique Values: 1315\n",
      "Column: CONQTY, Unique Values: 1312\n",
      "Column: INCNUM, Unique Values: 13147\n",
      "Column: INCLIN, Unique Values: 66\n",
      "Column: OUTNUM, Unique Values: 19753833\n",
      "Column: RELNUM, Unique Values: 12679882\n",
      "Column: LISNUM, Unique Values: 10328755\n",
      "Column: SUMLIS, Unique Values: 2714971\n",
      "Column: TRNNUM, Unique Values: 19832186\n",
      "Column: CRTDAT, Unique Values: 2121166\n",
      "Column: TRNDAT, Unique Values: 13955860\n",
      "Column: USERID, Unique Values: 426\n",
      "Column: VOLREQ, Unique Values: 252994\n",
      "Column: VOLPIC, Unique Values: 252466\n",
      "Column: LOADDAT, Unique Values: 411\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `df` is your DataFrame\n",
    "# Count unique values in each column\n",
    "unique_counts = df.nunique()\n",
    "\n",
    "# Display the unique value counts\n",
    "for column, count in unique_counts.items():\n",
    "    print(f\"Column: {column}, Unique Values: {count}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-25T14:10:47.161739Z",
     "start_time": "2024-11-25T14:09:54.959415Z"
    }
   },
   "id": "fcb3d1155f3e013c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dde91c6bb63eb0f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
