{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### All copied from final_dataprep_v1.ipynb to testrun fully and merge the df on FK and PKs for first usecase",
   "id": "79950e80aaecd0be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bewegungen.csv prep",
   "id": "52a6ed4c6ae38002"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c635ace25537efef"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-27T19:59:24.183486Z",
     "start_time": "2024-12-27T19:57:48.473596Z"
    }
   },
   "source": [
    "# consolidated :::\n",
    "import pandas as pd\n",
    "from idna.idnadata import joining_types\n",
    "\n",
    "# List of columns to keep (ran into memory issues...)\n",
    "columns_to_keep = [\n",
    "    \"STATUS\", \"SRC_ITEM\", \"SRC_LOT\", \"SRC_QACODE\",\n",
    "    \"DST_QACODE\", \"SRC_WA\", \"SRC_X\", \"SRC_Y\", \"SRC_Z\", \"OUTNUM\",\n",
    "    \"LISNUM\", \"SUMLIS\", \"TRNNUM\", \"TRNDAT\", \"USERID\", #  \"WORNUM\", \"DST_LOT\", \"DST_WA\", \"LOADDAT\", \"CRTDAT\" not needed (just the date when its imported into DWH)\n",
    "]\n",
    "\n",
    "dtypes = {\n",
    "#    \"WORNUM\": \"int32\",\n",
    "    \"STATUS\": \"int32\",\n",
    "#    \"MOVTYP\": \"category\",\n",
    "#    \"MOVKEY\": \"category\",\n",
    "    \"SRC_ITEM\": \"category\",\n",
    "    \"SRC_LOT\": \"string\",\n",
    "    \"SRC_QACODE\": \"category\",\n",
    "    #\"DST_LOT\": \"string\",\n",
    "    \"DST_QACODE\": \"category\",\n",
    "    \"SRC_WA\": \"category\",\n",
    "    \"SRC_X\": \"category\",\n",
    "    \"SRC_Y\": \"category\",\n",
    "    \"SRC_Z\": \"category\",\n",
    "#    \"DST_WA\": \"category\",\n",
    "    \"CONQTY\": \"int32\",\n",
    "    \"OUTNUM\": \"int32\", # KEY\n",
    "#    \"RELNUM\": \"int32\",\n",
    "    \"LISNUM\": \"int32\",\n",
    "    \"SUMLIS\": \"int32\",\n",
    "    \"TRNNUM\": \"int32\",\n",
    "    \"USERID\": \"category\",\n",
    "}\n",
    "\n",
    "# Load the CSV with optimized settings, and only load necessary cols\n",
    "df_bewegungen = pd.read_csv(\n",
    "    '../Data/bewegungen.csv',\n",
    "    usecols=columns_to_keep,  # Only load the specified columns\n",
    "    dtype=dtypes, # use optimized, manually set data types\n",
    "    #usecols=columns_to_use,  # Only load required columns\n",
    "    parse_dates=[\"TRNDAT\"],\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Clean SRC_LOT column (Column \"Artikelcharge\", this LOT usually is a 3 digit int. An Article can have multiple LOTs. I simplify by removing leading zeros and clean up the column from wrong manual usererrors.\n",
    "#df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].fillna('').astype(str)  # Handle NaNs and convert to string\n",
    "#df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].apply(lambda x: '0' if x == '000' else x.lstrip('0'))  # Remove leading zeros\n",
    "#df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].apply(lambda x: x if x.isdigit() and len(x) <= 3 else None)  # Validate format\n",
    "# keep value if: consists of digits, and its length is less than or equal to 3 -- otherwise replace with none\n",
    "\n",
    "# Clean DST_LOT column\n",
    "#df_bewegungen['DST_LOT'] = df_bewegungen['DST_LOT'].fillna('').astype(str)  # Handle NaNs and convert to string\n",
    "#df_bewegungen['DST_LOT'] = df_bewegungen['DST_LOT'].apply(lambda x: '0' if x == '000' else x.lstrip('0'))  # Remove leading zeros\n",
    "#df_bewegungen['DST_LOT'] = df_bewegungen['DST_LOT'].apply(lambda x: x if x.isdigit() and len(x) <= 3 else None)  # Validate format\n",
    "# keep value if: consists of digits, and its length is less than or equal to 3 -- otherwise replace with none\n",
    "\n",
    "####\n",
    "# Data Cleaning\n",
    "####\n",
    "\n",
    "# Temporarily convert 'SRC_LOT' to string type for cleaning\n",
    "df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].astype(str)  # Convert Categorical to string\n",
    "# Clean and validate the SRC_LOT column\n",
    "def clean_lot(value):\n",
    "    value = value.lstrip('0') if value != '000' else value  # Remove leading zeros unless '000'\n",
    "    if value.isdigit() and 1 <= len(value) <= 3:           # Validate length (1 to 3 digits)\n",
    "        return value.zfill(3)                              # Pad with leading zeros to ensure 3 digits\n",
    "    return None                                            # Remove invalid entries\n",
    "\n",
    "df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].apply(clean_lot)\n",
    "# Convert back to Categorical if needed\n",
    "df_bewegungen['SRC_LOT'] = pd.Categorical(df_bewegungen['SRC_LOT'])\n",
    "\n",
    "# Clean STATUS column (10= Offen, 50= Bestätigt, 95= Storniert -- for my purposes I'm only interested in \"Bestätigt\" rows.\n",
    "# Filter the DataFrame to keep only rows with status == 50 (abgeschlossen)\n",
    "df_bewegungen = df_bewegungen[df_bewegungen['STATUS'] == 50]\n",
    "\n",
    "# Filter the DataFrame in place to include only rows where 'SRC_WA' contains \"WA\", excluding all 'WE', 'WA', 'AU' and 'UM' areas\n",
    "df_bewegungen = df_bewegungen[df_bewegungen['SRC_WA'] == 'EG']\n",
    "\n",
    "# Remove rows where USER == 'LXONE'\n",
    "df_bewegungen = df_bewegungen[df_bewegungen['USERID'] != 'LXONE']\n",
    "\n",
    "# Only keep rows with QACODE == 'H'\n",
    "df_bewegungen = df_bewegungen[df_bewegungen['SRC_QACODE'] == 'H']\n",
    "\n",
    "# Remove all additional Crossdocking movements, easiest to pinpoint via SRC_LOT = 000\n",
    "df_bewegungen = df_bewegungen[df_bewegungen['SRC_LOT'] != '000']\n",
    "\n",
    "\n",
    "df_bewegungen = df_bewegungen.astype({\n",
    "    \"SRC_LOT\": \"category\",\n",
    "#    \"DST_LOT\": \"category\",\n",
    "})\n",
    "\n",
    "# Drop rows with missing values from the DataFrame - dropna (by default, without parameters) removes entire rows which have a NaN or null value\n",
    "df_bewegungen.dropna(inplace=True)\n",
    "\n",
    "# Drop both 'SRC_WA' and 'DST_WA' columns from the DataFrame\n",
    "df_bewegungen.drop(columns=['STATUS', 'SRC_WA', 'SRC_QACODE'], inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(f\"Updated DataFrame shape: {df_bewegungen.shape}\")\n",
    "# :::"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame shape: (17914909, 12)\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T19:25:26.615086Z",
     "start_time": "2024-12-27T19:25:14.897760Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fc6e69f5cde58c79",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T19:57:20.779123Z",
     "start_time": "2024-12-27T19:57:20.575885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in SRC_WA\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_bewegungen['SRC_LOT'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_bewegungen['SRC_LOT'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'DST_WA' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)\n"
   ],
   "id": "f125ad4cef096d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 72 unique entries in the 'DST_WA' column.\n",
      "\n",
      "Occurrences of each unique entry:\n",
      "001    15984112\n",
      "000     1576942\n",
      "002      749870\n",
      "003      362855\n",
      "004      226203\n",
      "         ...   \n",
      "045          57\n",
      "077          50\n",
      "035          38\n",
      "051          13\n",
      "223           1\n",
      "Name: SRC_LOT, Length: 72, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T19:37:11.181730Z",
     "start_time": "2024-12-27T19:37:11.136789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in STATUS\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_bewegungen['SRC_QACODE'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_bewegungen['SRC_QACODE'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'SRC_QACODE' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)"
   ],
   "id": "cf3e08e49d99c95a",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SRC_QACODE'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3360\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3361\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'SRC_QACODE'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_5060\\618816945.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m####\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# Count the number of unique entries in the 'SRC_WA' column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0munique_entries_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_bewegungen\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'SRC_QACODE'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnunique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# Count the occurrences of each unique entry in the 'SRC_WA' column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3456\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3457\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3458\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3459\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3460\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3361\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3363\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3364\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3365\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'SRC_QACODE'"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T19:37:35.917355Z",
     "start_time": "2024-12-27T19:37:35.887328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in SRC_QACODE\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_bewegungen['DST_LOT'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_bewegungen['DST_LOT'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'SRC_QACODE' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)"
   ],
   "id": "407bddc4286bd05f",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DST_LOT'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3360\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3361\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'DST_LOT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_5060\\4242034765.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m####\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# Count the number of unique entries in the 'SRC_WA' column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0munique_entries_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_bewegungen\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'DST_LOT'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnunique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# Count the occurrences of each unique entry in the 'SRC_WA' column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3456\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3457\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3458\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3459\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3460\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3361\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3363\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3364\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3365\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'DST_LOT'"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T21:46:00.381078Z",
     "start_time": "2024-12-27T21:46:00.354053Z"
    }
   },
   "cell_type": "code",
   "source": "df_bewegungen.head()",
   "id": "411ad1880fd30d99",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   SRC_ITEM SRC_LOT DST_QACODE SRC_X SRC_Y SRC_Z    OUTNUM     LISNUM  \\\n",
       "0  36529803     001          H  1601    02   D15  31313376  289679194   \n",
       "1  44118619     001          H  1780    02   E03  31320349  289874022   \n",
       "2  13091411     001          H  2215    04   F13  31324968  289835037   \n",
       "4  16359571     001          H  2004    07   G05  31346782  289840157   \n",
       "5  38789620     001          H  0112    08  BA05  31344732  289808077   \n",
       "\n",
       "      SUMLIS     TRNNUM              TRNDAT   USERID  \n",
       "0  289679311  599324284 2024-04-25 08:16:39    24769  \n",
       "1  289874463  599670338 2024-04-25 19:29:47   178141  \n",
       "2  289835121  599596179 2024-04-25 16:42:37  LAESSIG  \n",
       "4  289725531  599576127 2024-04-25 16:03:15   104044  \n",
       "5  289726826  599529006 2024-04-25 14:44:06   170056  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC_ITEM</th>\n",
       "      <th>SRC_LOT</th>\n",
       "      <th>DST_QACODE</th>\n",
       "      <th>SRC_X</th>\n",
       "      <th>SRC_Y</th>\n",
       "      <th>SRC_Z</th>\n",
       "      <th>OUTNUM</th>\n",
       "      <th>LISNUM</th>\n",
       "      <th>SUMLIS</th>\n",
       "      <th>TRNNUM</th>\n",
       "      <th>TRNDAT</th>\n",
       "      <th>USERID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36529803</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>1601</td>\n",
       "      <td>02</td>\n",
       "      <td>D15</td>\n",
       "      <td>31313376</td>\n",
       "      <td>289679194</td>\n",
       "      <td>289679311</td>\n",
       "      <td>599324284</td>\n",
       "      <td>2024-04-25 08:16:39</td>\n",
       "      <td>24769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44118619</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>1780</td>\n",
       "      <td>02</td>\n",
       "      <td>E03</td>\n",
       "      <td>31320349</td>\n",
       "      <td>289874022</td>\n",
       "      <td>289874463</td>\n",
       "      <td>599670338</td>\n",
       "      <td>2024-04-25 19:29:47</td>\n",
       "      <td>178141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13091411</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>2215</td>\n",
       "      <td>04</td>\n",
       "      <td>F13</td>\n",
       "      <td>31324968</td>\n",
       "      <td>289835037</td>\n",
       "      <td>289835121</td>\n",
       "      <td>599596179</td>\n",
       "      <td>2024-04-25 16:42:37</td>\n",
       "      <td>LAESSIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16359571</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>2004</td>\n",
       "      <td>07</td>\n",
       "      <td>G05</td>\n",
       "      <td>31346782</td>\n",
       "      <td>289840157</td>\n",
       "      <td>289725531</td>\n",
       "      <td>599576127</td>\n",
       "      <td>2024-04-25 16:03:15</td>\n",
       "      <td>104044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38789620</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>0112</td>\n",
       "      <td>08</td>\n",
       "      <td>BA05</td>\n",
       "      <td>31344732</td>\n",
       "      <td>289808077</td>\n",
       "      <td>289726826</td>\n",
       "      <td>599529006</td>\n",
       "      <td>2024-04-25 14:44:06</td>\n",
       "      <td>170056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ? maybe remove _ check for NaN / missing values in DF",
   "id": "7e6bf76d9b261fe1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T11:22:11.281952Z",
     "start_time": "2024-12-25T11:22:10.041887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for null values\n",
    "# Total count of missing values in the DataFrame\n",
    "total_missing = df_bewegungen.isnull().sum().sum()\n",
    "print(f\"Total missing values in the DataFrame: {total_missing}\")\n",
    "\n",
    "# Filter DataFrame to show only rows with at least one missing value\n",
    "rows_with_missing_values = df_bewegungen[df_bewegungen.isnull().any(axis=1)]\n",
    "\n",
    "# Display the rows with missing values\n",
    "print(rows_with_missing_values)"
   ],
   "id": "a2ee7af9e21f8e96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in the DataFrame: 0\n",
      "Empty DataFrame\n",
      "Columns: [WORNUM, STATUS, SRC_ITEM, SRC_LOT, SRC_QACODE, DST_LOT, DST_QACODE, SRC_WA, SRC_X, SRC_Y, SRC_Z, DST_WA, OUTNUM, LISNUM, SUMLIS, TRNNUM, CRTDAT, TRNDAT, USERID, LOADDAT]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# WA kopf.csv prep",
   "id": "d3c1bdce32eb89b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:49:00.805392Z",
     "start_time": "2024-12-27T17:48:14.482084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Consolidated:::\n",
    "# List of columns to keep (ran into memory issues...)\n",
    "columns_to_keep = [\n",
    "    \"OUTNUM\", \"DOCNUM\", \"STATUS\", \"PICCOD\", \"CUSNUM\",\n",
    "    \"SHPTYP\", \"TOUR\", # \"TRNDAT\" \"CRTDAT\", \"ORDDAT\", \"DLVDAT\", not needed rn\n",
    "]\n",
    "\n",
    "dtypes = {\n",
    "    \"OUTNUM\": \"int32\", # KEY\n",
    "    \"DOCNUM\": \"category\", # Warenausgangsnummer\n",
    "    # \"ORDNUM\": \"category\", # dont think i need this, seems it achieves the same as DOCNUM\n",
    "    \"STATUS\": \"int32\",\n",
    "    \"PICCOD\": \"category\",\n",
    "    \"CUSNUM\": \"category\", # kunde\n",
    "    \"SHPTYP\": \"category\", # versandart\n",
    "    \"TOUR\": \"category\",\n",
    "}\n",
    "\n",
    "df_wa_kopf = pd.read_csv(\n",
    "    '../Data/wa_kopf.csv',\n",
    "    usecols=columns_to_keep,  # Only load the specified columns\n",
    "    dtype=dtypes,\n",
    "    #usecols=columns_to_use,  # Only load required columns\n",
    "    #dtype=dtypes,            # Use optimized data types\n",
    "    # parse_dates=[\"TRNDAT\"], # \"ORDDAT\", \"DLVDAT\", \"CRTDAT\",  not needed rn\n",
    "    low_memory=False\n",
    ")\n",
    "# Filter the DataFrame to keep only rows with status == 90 (abgeschlossene)\n",
    "df_wa_kopf = df_wa_kopf[df_wa_kopf['STATUS'] == 90]\n",
    "\n",
    "# Drop rows with missing values from the DataFrame - some early data and regression tests lead to PICCOD, SHPTYP and TOUR being empty (~86 rows)\n",
    "df_wa_kopf.dropna(inplace=True) # inplace=True modifies DataFrame directly without having to create a new one\n",
    "\n",
    "# Step 1: Merge main DataFrame with customers\n",
    "# df_orders = pd.merge(df_bewegungen, df_wa_kopf, on='OUTNUM', how='inner')\n",
    "\n",
    "#:::"
   ],
   "id": "aeff0654c5b44462",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T14:16:41.602967Z",
     "start_time": "2024-12-26T14:16:40.898712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for null values\n",
    "# Total count of missing values in the DataFrame\n",
    "total_missing = df_wa_kopf.isnull().sum().sum()\n",
    "print(f\"Total missing values in the DataFrame: {total_missing}\")\n",
    "\n",
    "# Filter DataFrame to show only rows with at least one missing value\n",
    "rows_with_missing_values = df_wa_kopf[df_wa_kopf.isnull().any(axis=1)]\n",
    "\n",
    "# Display the rows with missing values\n",
    "print(rows_with_missing_values)"
   ],
   "id": "243ea4cb85c57e28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in the DataFrame: 0\n",
      "Empty DataFrame\n",
      "Columns: [OUTNUM, DOCNUM, STATUS, PICCOD, CUSNUM, ORDDAT, DLVDAT, SHPTYP, TOUR, CRTDAT, TRNDAT]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T21:51:22.160077Z",
     "start_time": "2024-12-27T21:51:20.113910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in SRC_WA\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_wa_kopf['OUTNUM'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_wa_kopf['OUTNUM'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'OUTNUM' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)"
   ],
   "id": "39e57834bc2069c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19314904 unique entries in the 'OUTNUM' column.\n",
      "\n",
      "Occurrences of each unique entry:\n",
      "30723507    1\n",
      "31429611    1\n",
      "31418553    1\n",
      "31422515    1\n",
      "31418440    1\n",
      "           ..\n",
      "22136170    1\n",
      "22136169    1\n",
      "22136168    1\n",
      "22136167    1\n",
      "35224902    1\n",
      "Name: OUTNUM, Length: 19314904, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T21:51:48.150748Z",
     "start_time": "2024-12-27T21:51:41.277966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in SRC_WA\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_wa_kopf['DOCNUM'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_wa_kopf['DOCNUM'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'ORDNUM' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)"
   ],
   "id": "e444b52da219d317",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5965848 unique entries in the 'ORDNUM' column.\n",
      "\n",
      "Occurrences of each unique entry:\n",
      "28377289    5002\n",
      "28109999    3890\n",
      "28055543    3847\n",
      "28168002    3829\n",
      "28062966    3718\n",
      "            ... \n",
      "28592674       0\n",
      "28592676       0\n",
      "34653261       0\n",
      "34653258       0\n",
      "34656371       0\n",
      "Name: DOCNUM, Length: 5970945, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T21:46:16.183588Z",
     "start_time": "2024-12-27T21:46:16.172579Z"
    }
   },
   "cell_type": "code",
   "source": "df_wa_kopf.head()",
   "id": "49e9e5c3991b509b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     OUTNUM    DOCNUM  STATUS  PICCOD  CUSNUM SHPTYP TOUR\n",
       "0  30723507  33054472      90    BS17  100986     02   85\n",
       "1  30711706  33052260      90    BS17   94536     02   85\n",
       "2  30730649  33056533      90    BS17   90715     02   83\n",
       "3  30712103  33052611      90  BS15-S  165269    124   00\n",
       "4  30733401  33057203      90    BS17    2542     02   94"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUTNUM</th>\n",
       "      <th>DOCNUM</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>PICCOD</th>\n",
       "      <th>CUSNUM</th>\n",
       "      <th>SHPTYP</th>\n",
       "      <th>TOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30723507</td>\n",
       "      <td>33054472</td>\n",
       "      <td>90</td>\n",
       "      <td>BS17</td>\n",
       "      <td>100986</td>\n",
       "      <td>02</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30711706</td>\n",
       "      <td>33052260</td>\n",
       "      <td>90</td>\n",
       "      <td>BS17</td>\n",
       "      <td>94536</td>\n",
       "      <td>02</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30730649</td>\n",
       "      <td>33056533</td>\n",
       "      <td>90</td>\n",
       "      <td>BS17</td>\n",
       "      <td>90715</td>\n",
       "      <td>02</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30712103</td>\n",
       "      <td>33052611</td>\n",
       "      <td>90</td>\n",
       "      <td>BS15-S</td>\n",
       "      <td>165269</td>\n",
       "      <td>124</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30733401</td>\n",
       "      <td>33057203</td>\n",
       "      <td>90</td>\n",
       "      <td>BS17</td>\n",
       "      <td>2542</td>\n",
       "      <td>02</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    # WA Positionen prep",
   "id": "de563cba443df1db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:51:32.022957Z",
     "start_time": "2024-12-27T17:50:59.420175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Consolidated\n",
    "\n",
    "# List of columns to keep (ran into memory issues...)\n",
    "columns_to_keep = [\n",
    "    \"OUTNUM\", \"STATUS\", \"ITEM\", \"LOT\",\n",
    "    \"ORDQTY\", \"CONQTY\", \"USERID\", \"TRNNUM\" #  \"TRNDAT\", \"CRTDAT\", not needed rn\n",
    "]\n",
    "\n",
    "dtypes = {\n",
    "    #\"OUTLIN\": \"int32\", -- not used, useless column\n",
    "    \"OUTNUM\": \"int32\",\n",
    "    \"STATUS\": \"int32\",\n",
    "    \"ITEM\": \"category\",\n",
    "    \"LOT\": \"string\", # 3 character string, e.G: 001, 002, 006, 012 etc.\n",
    "    \"ORDQTY\": \"int32\",\n",
    "    \"CONQTY\": \"float32\", # somehow it thinks these values are float data\n",
    "    \"USERID\": \"category\",\n",
    "    \"TRNNUM\": \"int32\"\n",
    "}\n",
    "\n",
    "# Load the CSV with optimized settings, and only load necessary cols\n",
    "df_wa_positionen = pd.read_csv(\n",
    "    '../Data/wa_positionen.csv',\n",
    "    usecols=columns_to_keep,  # Only load the specified columns\n",
    "    dtype=dtypes,\n",
    "    #usecols=columns_to_use,  # Only load required columns\n",
    "    #dtype=dtypes,            # Use optimized data types\n",
    "    # parse_dates=[\"TRNDAT\"], # \"CRTDAT\", not needed rn\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Drop rows with missing values from the DataFrame\n",
    "df_wa_positionen.dropna(inplace=True)\n",
    "\n",
    "# Drop rows where CONQTY has a fractional part (i.e., a value with anything after the decimal point)\n",
    "df_wa_positionen = df_wa_positionen[df_wa_positionen[\"CONQTY\"] % 1 == 0]\n",
    "\n",
    "# Convert CONQTY column to integer type to reflect that it no longer has fractions\n",
    "df_wa_positionen[\"CONQTY\"] = df_wa_positionen[\"CONQTY\"].astype(int)\n",
    "\n",
    "## WRITE TO CSV todo\n",
    "\n",
    "# :::"
   ],
   "id": "51ccd801a9f8c734",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:52:51.576001Z",
     "start_time": "2024-12-27T17:52:51.560988Z"
    }
   },
   "cell_type": "code",
   "source": "df_wa_positionen.head()",
   "id": "3cbb1d6e9f605452",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     OUTNUM  STATUS      ITEM  LOT  ORDQTY  CONQTY      USERID     TRNNUM\n",
       "0   9684339      90   4299149  003      11       7  PASAMONTES  536001122\n",
       "1  10756704      90  28872808  002      83      83      168388  807604606\n",
       "2  10756724      90  19020166  006      40      40      168388  807604231\n",
       "3  11244298      90  35282807  001       3       3      MUAMET  518249888\n",
       "4  11244340      90  35448829  001       4       4      MUAMET  518249888"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUTNUM</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ITEM</th>\n",
       "      <th>LOT</th>\n",
       "      <th>ORDQTY</th>\n",
       "      <th>CONQTY</th>\n",
       "      <th>USERID</th>\n",
       "      <th>TRNNUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9684339</td>\n",
       "      <td>90</td>\n",
       "      <td>4299149</td>\n",
       "      <td>003</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>PASAMONTES</td>\n",
       "      <td>536001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10756704</td>\n",
       "      <td>90</td>\n",
       "      <td>28872808</td>\n",
       "      <td>002</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>168388</td>\n",
       "      <td>807604606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10756724</td>\n",
       "      <td>90</td>\n",
       "      <td>19020166</td>\n",
       "      <td>006</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>168388</td>\n",
       "      <td>807604231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11244298</td>\n",
       "      <td>90</td>\n",
       "      <td>35282807</td>\n",
       "      <td>001</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>MUAMET</td>\n",
       "      <td>518249888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11244340</td>\n",
       "      <td>90</td>\n",
       "      <td>35448829</td>\n",
       "      <td>001</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>MUAMET</td>\n",
       "      <td>518249888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T21:57:59.722162Z",
     "start_time": "2024-12-27T21:57:58.361292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in SRC_QACODE\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_wa_positionen['LOT'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_wa_positionen['LOT'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'SRC_QACODE' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)"
   ],
   "id": "3469659e165c1b6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 80 unique entries in the 'SRC_QACODE' column.\n",
      "\n",
      "Occurrences of each unique entry:\n",
      "001      15432416\n",
      "000       2097906\n",
      "002        717644\n",
      "003        346643\n",
      "004        215649\n",
      "           ...   \n",
      "0016            5\n",
      "1001            2\n",
      "223             1\n",
      ".001            1\n",
      "de001           1\n",
      "Name: LOT, Length: 80, dtype: Int64\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:52:03.663317Z",
     "start_time": "2024-12-27T17:52:02.015758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for null values\n",
    "# Total count of missing values in the DataFrame\n",
    "total_missing = df_wa_positionen.isnull().sum().sum()\n",
    "print(f\"Total missing values in the DataFrame: {total_missing}\")\n",
    "\n",
    "# Filter DataFrame to show only rows with at least one missing value\n",
    "rows_with_missing_values = df_wa_positionen[df_wa_positionen.isnull().any(axis=1)]\n",
    "\n",
    "# Display the rows with missing values\n",
    "print(rows_with_missing_values)"
   ],
   "id": "61001d33cc0378f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in the DataFrame: 0\n",
      "Empty DataFrame\n",
      "Columns: [OUTNUM, STATUS, ITEM, LOT, ORDQTY, CONQTY, USERID, TRNNUM]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:53:10.318779Z",
     "start_time": "2024-12-27T17:53:10.204676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter rows where CONQTY contains an actual float value\n",
    "float_rows = df_wa_positionen[df_wa_positionen[\"CONQTY\"] % 1 != 0]\n",
    "\n",
    "# Display the rows with float values in CONQTY\n",
    "print(\"Rows with actual float values in the CONQTY column:\")\n",
    "print(float_rows)"
   ],
   "id": "a3dba9ccea042401",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with actual float values in the CONQTY column:\n",
      "Empty DataFrame\n",
      "Columns: [OUTNUM, STATUS, ITEM, LOT, ORDQTY, CONQTY, USERID, TRNNUM]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:53:16.431652Z",
     "start_time": "2024-12-27T17:53:16.423645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count_float_values = len(float_rows)\n",
    "print(f\"Number of rows with float values in CONQTY: {count_float_values}\")"
   ],
   "id": "d20991fd66a8ddb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with float values in CONQTY: 0\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Joins",
   "id": "6260fb5bf5fd1d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# = pd.merge(df_bewegungen, df_wa_kopf, on='OUTNUM', how='inner')\n"
   ],
   "id": "810e35cc4cb03fbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:00:59.088736Z",
     "start_time": "2024-12-27T22:00:41.209115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_full = (\n",
    "    pd.merge(df_bewegungen, df_wa_kopf, on='OUTNUM', how='inner')\n",
    "    .merge(df_wa_positionen, on='OUTNUM', how='inner')\n",
    ")\n",
    "\n",
    "print(df_full.head())\n"
   ],
   "id": "d81963a2ec8a920d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SRC_ITEM SRC_LOT DST_QACODE SRC_X SRC_Y SRC_Z    OUTNUM     LISNUM  \\\n",
      "0  36529803     001          H  1601    02   D15  31313376  289679194   \n",
      "1  44118619     001          H  1780    02   E03  31320349  289874022   \n",
      "2  13091411     001          H  2215    04   F13  31324968  289835037   \n",
      "3  16359571     001          H  2004    07   G05  31346782  289840157   \n",
      "4  38789620     001          H  0112    08  BA05  31344732  289808077   \n",
      "\n",
      "      SUMLIS   TRNNUM_x  ...  CUSNUM SHPTYP TOUR  STATUS_y      ITEM  LOT  \\\n",
      "0  289679311  599324284  ...   83055     02   93        90  36529803  001   \n",
      "1  289874463  599670338  ...  164073     02   95        90  44118619  001   \n",
      "2  289835121  599596179  ...   34858     07   52        90  13091411  001   \n",
      "3  289725531  599576127  ...   30804     02   96        90  16359571  001   \n",
      "4  289726826  599529006  ...   13105     07   59        90  38789620  001   \n",
      "\n",
      "  ORDQTY CONQTY  USERID_y   TRNNUM_y  \n",
      "0      9      9     LXONE  599670642  \n",
      "1      2      2     LXONE  599678660  \n",
      "2      1      1     LXONE  599659813  \n",
      "3      1      1     LXONE  599659634  \n",
      "4      1      1     LXONE  599652028  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T21:55:44.247752Z",
     "start_time": "2024-12-27T21:55:44.229546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_full.head()\n",
    "df_full.info()"
   ],
   "id": "18957fb0431e8f8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19628916 entries, 0 to 19628915\n",
      "Data columns (total 31 columns):\n",
      " #   Column      Dtype         \n",
      "---  ------      -----         \n",
      " 0   WORNUM      int32         \n",
      " 1   STATUS_x    int32         \n",
      " 2   SRC_ITEM    category      \n",
      " 3   SRC_LOT     category      \n",
      " 4   SRC_QACODE  category      \n",
      " 5   DST_LOT     category      \n",
      " 6   DST_QACODE  category      \n",
      " 7   SRC_WA      category      \n",
      " 8   SRC_X       category      \n",
      " 9   SRC_Y       category      \n",
      " 10  SRC_Z       category      \n",
      " 11  DST_WA      category      \n",
      " 12  OUTNUM      int32         \n",
      " 13  LISNUM      int32         \n",
      " 14  SUMLIS      int32         \n",
      " 15  TRNNUM_x    int32         \n",
      " 16  TRNDAT      datetime64[ns]\n",
      " 17  USERID_x    category      \n",
      " 18  DOCNUM      category      \n",
      " 19  STATUS_y    int32         \n",
      " 20  PICCOD      category      \n",
      " 21  CUSNUM      category      \n",
      " 22  SHPTYP      category      \n",
      " 23  TOUR        category      \n",
      " 24  STATUS      int32         \n",
      " 25  ITEM        category      \n",
      " 26  LOT         string        \n",
      " 27  ORDQTY      int32         \n",
      " 28  CONQTY      int32         \n",
      " 29  USERID_y    category      \n",
      " 30  TRNNUM_y    int32         \n",
      "dtypes: category(18), datetime64[ns](1), int32(11), string(1)\n",
      "memory usage: 2.1 GB\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:01:07.390923Z",
     "start_time": "2024-12-27T22:01:07.376911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_rows = len(df_full)\n",
    "print(f\"Number of rows: {num_rows}\")"
   ],
   "id": "fd6c62a2759ea196",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 17505630\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T14:34:03.077301Z",
     "start_time": "2024-12-26T14:33:58.610689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for null values\n",
    "# Total count of missing values in the DataFrame\n",
    "total_missing = df_full.isnull().sum().sum()\n",
    "print(f\"Total missing values in the DataFrame: {total_missing}\")\n",
    "\n",
    "# Filter DataFrame to show only rows with at least one missing value\n",
    "rows_with_missing_values = df_full[df_full.isnull().any(axis=1)]\n",
    "\n",
    "# Display the rows with missing values\n",
    "print(rows_with_missing_values)"
   ],
   "id": "28637ed8ef7e0298",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in the DataFrame: 0\n",
      "Empty DataFrame\n",
      "Columns: [WORNUM, STATUS_x, SRC_ITEM, SRC_LOT, SRC_QACODE, DST_LOT, DST_QACODE, SRC_WA, SRC_X, SRC_Y, SRC_Z, DST_WA, OUTNUM, LISNUM, SUMLIS, TRNNUM_x, CRTDAT_x, TRNDAT_x, USERID_x, DOCNUM, STATUS_y, PICCOD, CUSNUM, ORDDAT, DLVDAT, SHPTYP, TOUR, CRTDAT_y, TRNDAT_y, STATUS, ITEM, LOT, ORDQTY, CONQTY, CRTDAT, TRNDAT, USERID_y, TRNNUM_y]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 38 columns]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Export Dataframe to Parquet file",
   "id": "13c626012ee82467"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T14:33:35.442002Z",
     "start_time": "2024-12-26T14:33:10.048477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyarrow\n",
    "\n",
    "# Save the fully joined DataFrame to a Parquet file for better performance\n",
    "output_file = 'joined_data_v2.parquet'\n",
    "df_full.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"Fully joined DataFrame saved to {output_file}\")"
   ],
   "id": "3f0a3f4ed86413ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully joined DataFrame saved to joined_data_v2.parquet\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# reading parquet file later\n",
    "\n",
    "df_loaded = pd.read_parquet('joined_data.parquet')\n",
    "print(df_loaded.head())\n"
   ],
   "id": "d51518b2e64392a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##TEMP\n",
   "id": "f55023219bdda426"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T21:56:19.403878Z",
     "start_time": "2024-12-27T21:56:19.376744Z"
    }
   },
   "cell_type": "code",
   "source": "df_full.head()",
   "id": "d980f5634eeda664",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      WORNUM  STATUS_x  SRC_ITEM SRC_LOT SRC_QACODE DST_LOT DST_QACODE SRC_WA  \\\n",
       "0  289678987        50  36529803       1          H       1          H     EG   \n",
       "1  289870561        50  44118619       1          H       1          H     EG   \n",
       "2  289833599        50  13091411       1          H       1          H     EG   \n",
       "3  289815259        50   9636829       0          H       0          H     EG   \n",
       "4  289839097        50  16359571       1          H       1          H     EG   \n",
       "\n",
       "  SRC_X SRC_Y  ...  CUSNUM SHPTYP  TOUR  STATUS      ITEM  LOT ORDQTY CONQTY  \\\n",
       "0  1601    02  ...   83055     02    93      90  36529803  001      9      9   \n",
       "1  1780    02  ...  164073     02    95      90  44118619  001      2      2   \n",
       "2  2215    04  ...   34858     07    52      90  13091411  001      1      1   \n",
       "3  2401    02  ...   94180     07    52      90   9636829  000      1      1   \n",
       "4  2004    07  ...   30804     02    96      90  16359571  001      1      1   \n",
       "\n",
       "  USERID_y   TRNNUM_y  \n",
       "0    LXONE  599670642  \n",
       "1    LXONE  599678660  \n",
       "2    LXONE  599659813  \n",
       "3    LXONE  599669523  \n",
       "4    LXONE  599659634  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORNUM</th>\n",
       "      <th>STATUS_x</th>\n",
       "      <th>SRC_ITEM</th>\n",
       "      <th>SRC_LOT</th>\n",
       "      <th>SRC_QACODE</th>\n",
       "      <th>DST_LOT</th>\n",
       "      <th>DST_QACODE</th>\n",
       "      <th>SRC_WA</th>\n",
       "      <th>SRC_X</th>\n",
       "      <th>SRC_Y</th>\n",
       "      <th>...</th>\n",
       "      <th>CUSNUM</th>\n",
       "      <th>SHPTYP</th>\n",
       "      <th>TOUR</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ITEM</th>\n",
       "      <th>LOT</th>\n",
       "      <th>ORDQTY</th>\n",
       "      <th>CONQTY</th>\n",
       "      <th>USERID_y</th>\n",
       "      <th>TRNNUM_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289678987</td>\n",
       "      <td>50</td>\n",
       "      <td>36529803</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>EG</td>\n",
       "      <td>1601</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>83055</td>\n",
       "      <td>02</td>\n",
       "      <td>93</td>\n",
       "      <td>90</td>\n",
       "      <td>36529803</td>\n",
       "      <td>001</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>LXONE</td>\n",
       "      <td>599670642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289870561</td>\n",
       "      <td>50</td>\n",
       "      <td>44118619</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>EG</td>\n",
       "      <td>1780</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>164073</td>\n",
       "      <td>02</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>44118619</td>\n",
       "      <td>001</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>LXONE</td>\n",
       "      <td>599678660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289833599</td>\n",
       "      <td>50</td>\n",
       "      <td>13091411</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>EG</td>\n",
       "      <td>2215</td>\n",
       "      <td>04</td>\n",
       "      <td>...</td>\n",
       "      <td>34858</td>\n",
       "      <td>07</td>\n",
       "      <td>52</td>\n",
       "      <td>90</td>\n",
       "      <td>13091411</td>\n",
       "      <td>001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LXONE</td>\n",
       "      <td>599659813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289815259</td>\n",
       "      <td>50</td>\n",
       "      <td>9636829</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>EG</td>\n",
       "      <td>2401</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>94180</td>\n",
       "      <td>07</td>\n",
       "      <td>52</td>\n",
       "      <td>90</td>\n",
       "      <td>9636829</td>\n",
       "      <td>000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LXONE</td>\n",
       "      <td>599669523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289839097</td>\n",
       "      <td>50</td>\n",
       "      <td>16359571</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>EG</td>\n",
       "      <td>2004</td>\n",
       "      <td>07</td>\n",
       "      <td>...</td>\n",
       "      <td>30804</td>\n",
       "      <td>02</td>\n",
       "      <td>96</td>\n",
       "      <td>90</td>\n",
       "      <td>16359571</td>\n",
       "      <td>001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LXONE</td>\n",
       "      <td>599659634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Machine Learning\n",
   "id": "b168358213f6db00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:55:18.204138Z",
     "start_time": "2024-12-27T17:55:18.195130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encoding\n",
    "columns_and_types = df_full.dtypes.reset_index()\n",
    "columns_and_types.columns = ['Column', 'Data Type']\n",
    "\n",
    "# Display the table\n",
    "print(columns_and_types)"
   ],
   "id": "6e010e44af551a1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column       Data Type\n",
      "0       WORNUM           int32\n",
      "1     STATUS_x           int32\n",
      "2     SRC_ITEM        category\n",
      "3      SRC_LOT        category\n",
      "4   SRC_QACODE        category\n",
      "5      DST_LOT        category\n",
      "6   DST_QACODE        category\n",
      "7       SRC_WA        category\n",
      "8        SRC_X        category\n",
      "9        SRC_Y        category\n",
      "10       SRC_Z        category\n",
      "11      DST_WA        category\n",
      "12      OUTNUM           int32\n",
      "13      LISNUM           int32\n",
      "14      SUMLIS           int32\n",
      "15    TRNNUM_x           int32\n",
      "16      TRNDAT  datetime64[ns]\n",
      "17    USERID_x        category\n",
      "18      DOCNUM        category\n",
      "19    STATUS_y           int32\n",
      "20      PICCOD        category\n",
      "21      CUSNUM        category\n",
      "22      SHPTYP        category\n",
      "23        TOUR        category\n",
      "24      STATUS           int32\n",
      "25        ITEM        category\n",
      "26         LOT          string\n",
      "27      ORDQTY           int32\n",
      "28      CONQTY           int32\n",
      "29    USERID_y        category\n",
      "30    TRNNUM_y           int32\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "240d2bfa06d3367f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
