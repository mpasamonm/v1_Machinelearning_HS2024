{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_sample = pd.read_csv('../Data/bewegungen.csv', nrows=100)\n",
    "print(df_sample.head())\n",
    "print(df_sample.info())\n"
   ],
   "id": "fe667966f6178eef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Code to check which columns have mixed types due to error while loading csv\n",
    "import pandas as pd\n",
    "\n",
    "# Load a small chunk of the file or the whole file\n",
    "df = pd.read_csv('../Data/bewegungen.csv')\n",
    "\n",
    "# Specify the columns expected to be numeric\n",
    "numeric_columns = [\"SRC_X\", \"SRC_Y\", \"DST_X\", \"DST_Y\", \"REQQTY\", \"CONQTY\"]\n",
    "\n",
    "# Iterate through each numeric column and find non-numeric values\n",
    "for column in numeric_columns:\n",
    "    non_numeric = df[~df[column].apply(lambda x: str(x).replace('.', '', 1).isdigit())]\n",
    "    if not non_numeric.empty:\n",
    "        print(f\"Non-numeric values found in column '{column}':\")\n",
    "        print(non_numeric[[column]].head())  # Show examples of non-numeric rows\n"
   ],
   "id": "19790cba7e97903d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cleanup bewegungen.csv -> adjust dtype and load to parquet for more efficient access\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "\n",
    "# Adjusted dtype mapping\n",
    "df_bewegungen = pd.read_csv(\n",
    "    '../Data/bewegungen.csv',\n",
    "    dtype={\n",
    "        \"MOVNUM\": \"int64\",\n",
    "        \"WORNUM\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"MOVTYP\": \"category\",\n",
    "        \"MOVKEY\": \"category\",\n",
    "        \"SRC_ITEM\": \"category\", #category ideal - unique 900k articles, repeated articles IDs, column might be used for grouping, filtering and comparisons later on\n",
    "        \"SRC_LOT\": \"category\",\n",
    "        \"SRC_QACODE\": \"category\",\n",
    "        \"DST_LOT\": \"category\",\n",
    "        \"DST_QACODE\": \"category\",\n",
    "        \"SRC_WA\": \"category\",\n",
    "        \"DST_WA\": \"category\",\n",
    "        \"SRC_X\": \"object\",\n",
    "        \"SRC_Y\": \"object\",\n",
    "        \"SRC_Z\": \"category\",\n",
    "        \"DST_X\": \"object\", #always the same destination for X,Y and Z -> Warenausgang\n",
    "        \"DST_Y\": \"object\",\n",
    "        \"DST_Z\": \"category\",\n",
    "        \"REQQTY\": \"int64\",\n",
    "        \"CONQTY\": \"int64\",\n",
    "        \"INCNUM\": \"int64\",\n",
    "        \"LISNUM\": \"int64\",\n",
    "        \"USERID\": \"category\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"],\n",
    "    chunksize=100000  # Process large files in chunks\n",
    ")\n",
    "\n",
    "# Process chunks\n",
    "for chunk in df_bewegungen:\n",
    "    print(chunk.info())\n",
    "\n",
    "# Save to Parquet\n",
    "df.to_parquet('../Data/processed_bewegungen.parquet', index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "59b74116f2efdcfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the file in chunks\n",
    "chunk_iter = pd.read_csv(\n",
    "    '../Data/bewegungen.csv',\n",
    "    dtype={\n",
    "        \"SRC_LOT\": \"category\",  # Ensures memory efficiency for repetitive values\n",
    "    },\n",
    "    usecols=[\"SRC_LOT\"],  # Only load the SRC_LOT column\n",
    "    chunksize=100000      # Process in chunks\n",
    ")\n",
    "\n",
    "# Collect unique values from all chunks\n",
    "unique_values = set()\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    unique_values.update(chunk['SRC_LOT'].unique())\n",
    "\n",
    "# Convert the set to a sorted list and print the values\n",
    "unique_values = sorted(unique_values)\n",
    "print(\"Unique values in SRC_LOT column:\")\n",
    "print(unique_values)\n"
   ],
   "id": "9855183414076414",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unique_values_count = df['SRC_LOT'].nunique()\n",
    "print(f\"Number of unique values in SRC_LOT: {unique_values_count}\")\n",
    "unique_values = df['SRC_LOT'].unique()\n",
    "print(f\"Unique values in SRC_LOT: {unique_values}\")\n"
   ],
   "id": "4aa5d467bb7b4baf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Above output shows the issue that there is a mix of data types. Before I decide what to do with the outliers, I need to find out how these values are spread out.",
   "id": "1399f3c14a826373"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define a function to determine the type of each entry\n",
    "def get_dtype(value):\n",
    "    return type(value).__name__\n",
    "\n",
    "# Apply the function to the SRC_LOT column and count occurrences of each type\n",
    "type_counts = df['SRC_LOT'].apply(get_dtype).value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(\"Data types in SRC_LOT column:\")\n",
    "print(type_counts)\n"
   ],
   "id": "545e072ef06cdbbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I can most Data types are int and str, I wonder what the floats are - so I output them to a .csv file for me to see",
   "id": "47c721ae8167edcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "output_folder = r\"H:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\Data\\temp\"\n",
    "output_file = os.path.join(output_folder, \"float_values_in_src_lot_v2.csv\")\n",
    "\n",
    "# Function to identify floats in the SRC_LOT column\n",
    "def is_float(value):\n",
    "    return isinstance(value, float)\n",
    "\n",
    "# Filter rows where SRC_LOT contains floats\n",
    "float_values = df[df['SRC_LOT'].apply(is_float)]\n",
    "\n",
    "# Select only the columns you need (SRC_LOT and SRC_ITEM)\n",
    "float_values_filtered = float_values[['SRC_LOT', 'SRC_ITEM', 'CRTDAT']]\n",
    "\n",
    "# Save the results to the specified folder\n",
    "float_values_filtered.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"CSV file with float values in SRC_LOT saved at: {output_file}\")\n"
   ],
   "id": "1cfe035a722f7307",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The Data all has the same CRTDate from way back in 2022 traced back to the same day. I will remove these float values as i cannot validate their correctness.\n",
    "At the same time, I'm going to convert all values to strings for consitency before cleaning those up aswell"
   ],
   "id": "beaa09a4dab67c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter out float entries in the 'SRC_LOT' column\n",
    "df = df[~df['SRC_LOT'].apply(lambda x: isinstance(x, float))]\n",
    "\n",
    "# Convert all remaining values to integers (handling strings first)\n",
    "df['SRC_LOT'] = df['SRC_LOT'].apply(lambda x: int(float(x)) if isinstance(x, str) else x)\n",
    "\n",
    "# Save the cleaned dataset to a Parquet file\n",
    "df.to_parquet('cleaned_data.parquet', index=False)\n",
    "\n",
    "print(\"Data cleaned and saved to 'cleaned_data.parquet'.\")\n"
   ],
   "id": "8fa69b8725d6d2b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#check if null values are present\n",
    "round((df.isnull().sum()/df.shape[0])*100,2)"
   ],
   "id": "38b7e27b7f207933",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#count unique entries in each row of the table\n",
    "unique_counts = df.nunique()\n",
    "print(unique_counts)"
   ],
   "id": "fb9744e7049ee790",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5602a150fb1bb18c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read Bewegungen 1.1 (WMDT) - only PIC movements, otherwise the file would be too big (50gb+)\n",
    "df_bewegungen = pd.read_csv(\n",
    "    '../Data/bewegungen.csv',\n",
    "    dtype={\n",
    "        \"MOVNUM\": \"int64\",\n",
    "        \"WORNUM\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"MOVTYP\": \"category\",\n",
    "        \"MOVKEY\": \"category\",\n",
    "        \"SRC_ITEM\": \"category\", #category ideal - unique 900k articles, repeated articles IDs, column might be used for grouping, filtering and comparisons later on\n",
    "        \"SRC_LOT\": \"category\",\n",
    "        \"SRC_QACODE\": \"category\",\n",
    "        \"DST_LOT\": \"category\",\n",
    "        \"DST_QACODE\": \"category\",\n",
    "        \"SRC_WA\": \"category\",\n",
    "        \"DST_WA\": \"category\",\n",
    "        \"SRC_X\": \"object\",\n",
    "        \"SRC_Y\": \"object\",\n",
    "        \"SRC_Z\": \"category\",\n",
    "        \"DST_X\": \"object\", #always the same destination for X,Y and Z -> Warenausgang\n",
    "        \"DST_Y\": \"object\",\n",
    "        \"DST_Z\": \"category\",\n",
    "        \"REQQTY\": \"int64\",\n",
    "        \"CONQTY\": \"int64\",\n",
    "        \"INCNUM\": \"int64\",\n",
    "        \"LISNUM\": \"int64\",\n",
    "        \"USERID\": \"category\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"]\n",
    ")\n",
    "\n",
    "# Read Warenausgang Kopf 7a\n",
    "df_wa_kopf = pd.read_csv(\n",
    "    '../Data/wa_kopf.csv',\n",
    "    dtype={\n",
    "        \"OUTNUM\": \"int64\",\n",
    "        \"DOCNUM\": \"int64\",\n",
    "        \"ORDNUM\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"CUSNUM\": \"int64\",\n",
    "        \"SHPTYP\": \"category\",\n",
    "        \"TOUR\": \"int64\",\n",
    "    },\n",
    "    parse_dates=[\"ORDDAT\", \"DLVDAT\", \"CRTDAT\", \"TRNDAT\"]\n",
    ")\n",
    "\n",
    "# Read Warenausgang Positionen 7b\n",
    "df_wa_positionen = pd.read_csv(\n",
    "    '../Data/wa_positionen.csv',\n",
    "    dtype={\n",
    "        \"OUTNUM\": \"int64\",\n",
    "        \"OUTLIN\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"ITEM\": \"int64\",\n",
    "        \"LOT\": \"category\",\n",
    "        \"QACODE\": \"category\",\n",
    "        \"ORDQTY\": \"int64\",\n",
    "        \"RELQTY\": \"int64\",\n",
    "        \"FNDQTY\": \"int64\",\n",
    "        \"CONQTY\": \"int64\",\n",
    "        \"SHPQTY\": \"int64\",\n",
    "        \"USERID\": \"category\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"]\n",
    ")\n",
    "\n",
    "# Read Listen 8\n",
    "df_listen = pd.read_csv(\n",
    "    '../Data/listen.csv',\n",
    "    dtype={\n",
    "        \"LISNUM\": \"int64\",\n",
    "        \"SUMLIS\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"PRIO\": \"int64\",\n",
    "        \"PZ\": \"category\",\n",
    "        \"RELNUM\": \"int64\",\n",
    "        \"CUSNUM\": \"int64\",\n",
    "        \"DSPADR\": \"category\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"]\n",
    ")\n",
    "\n",
    "# Read Artikelbestand 5\n",
    "df_artikelbestand = pd.read_csv(\n",
    "    '../Data/artikelbestand.csv',\n",
    "    dtype={\n",
    "        \"OBJNUM\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"LOCNUM\": \"int64\",\n",
    "        \"PICLCK\": \"bool\",\n",
    "        \"STTLCK\": \"bool\",\n",
    "        \"ITEM\": \"int64\",\n",
    "        \"LOT\": \"category\",\n",
    "        \"INQTY\": \"int64\",\n",
    "        \"OUTQTY\": \"int64\",\n",
    "        \"AVLQTY\": \"int64\",\n",
    "        \"CONQTY\": \"int64\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"]\n",
    ")\n",
    "\n",
    "# Read Lagerplatz 3\n",
    "df_lagerplatz = pd.read_csv(\n",
    "    '../Data/lagerplatz.csv',\n",
    "    dtype={\n",
    "        \"OBJNUM\": \"int64\",\n",
    "        \"WH\": \"category\",\n",
    "        \"WA\": \"category\",\n",
    "        \"X\": \"int64\",\n",
    "        \"Y\": \"int64\",\n",
    "        \"Z\": \"object\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"PUTPRI\": \"int64\",\n",
    "        \"PICPRI\": \"int64\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"]\n",
    ")\n"
   ],
   "id": "f373e4dfb0042eec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display info for Bewegungen 1.1 (WMDT)\n",
    "print(\"Bewegungen 1.1 Info:\")\n",
    "print(df_bewegungen.info())\n",
    "\n",
    "# Display info for Warenausgang Kopf 7a\n",
    "print(\"\\nWarenausgang Kopf Info:\")\n",
    "print(df_wa_kopf.info())\n",
    "\n",
    "# Display info for Warenausgang Positionen 7b\n",
    "print(\"\\nWarenausgang Positionen Info:\")\n",
    "print(df_wa_positionen.info())\n",
    "\n",
    "# Display info for Listen 8\n",
    "print(\"\\nListen Info:\")\n",
    "print(df_listen.info())\n",
    "\n",
    "# Display info for Artikelbestand 5\n",
    "print(\"\\nArtikelbestand Info:\")\n",
    "print(df_artikelbestand.info())\n",
    "\n",
    "# Display info for Lagerplatz 3\n",
    "print(\"\\nLagerplatz Info:\")\n",
    "print(df_lagerplatz.info())\n"
   ],
   "id": "978727dd8db69317",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
