{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "take a small sample of data to get quick overview over the data and its structure",
   "id": "f743e69b644e596d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T10:52:42.788459Z",
     "start_time": "2024-11-25T10:52:41.122311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_sample = pd.read_csv('../Data/bewegungen.csv', nrows=100)\n",
    "print(df_sample.head())\n",
    "print(df_sample.info())\n"
   ],
   "id": "fe667966f6178eef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MOVNUM     WORNUM  STATUS MOVTYP MOVKEY  SRC_ITEM  SRC_LOT SRC_QACODE  \\\n",
      "0  289678988  289678987      50    REL    PIC  36529803        1          H   \n",
      "1  289870562  289870561      50    REL    PIC  44118619        1          H   \n",
      "2  289833600  289833599      50    REL    PIC  13091411        1          H   \n",
      "3  289815260  289815259      50    REL    PIC   9636829        0          H   \n",
      "4  289839098  289839097      50    REL    PIC  16359571        1          H   \n",
      "\n",
      "   DST_LOT DST_QACODE  ...    RELNUM     LISNUM     SUMLIS     TRNNUM  \\\n",
      "0        1          H  ...  41484834  289679194  289679311  599324284   \n",
      "1        1          H  ...  41494178  289874022  289874463  599670338   \n",
      "2        1          H  ...  41492163  289835037  289835121  599596179   \n",
      "3        0          H  ...  41491410  289815703  289815805  599541258   \n",
      "4        1          H  ...  41492589  289840157  289725531  599576127   \n",
      "\n",
      "                CRTDAT               TRNDAT    USERID   VOLREQ   VOLPIC  \\\n",
      "0  2024-04-25 01:04:53  2024-04-25 08:16:39     24769  1795500  1795500   \n",
      "1  2024-04-25 17:34:53  2024-04-25 19:29:47    178141  1065600  1065600   \n",
      "2  2024-04-25 15:24:37  2024-04-25 16:42:37   LAESSIG   696672   696672   \n",
      "3  2024-04-25 14:34:37  2024-04-25 14:56:15  GUERBUEZ   299376   299376   \n",
      "4  2024-04-25 15:39:56  2024-04-25 16:03:15    104044  1706600  1706600   \n",
      "\n",
      "                      LOADDAT  \n",
      "0  2024-04-26 00:52:47.247838  \n",
      "1  2024-04-26 00:52:47.247838  \n",
      "2  2024-04-26 00:52:47.247838  \n",
      "3  2024-04-26 00:52:47.247838  \n",
      "4  2024-04-26 00:52:47.247838  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   MOVNUM      100 non-null    int64 \n",
      " 1   WORNUM      100 non-null    int64 \n",
      " 2   STATUS      100 non-null    int64 \n",
      " 3   MOVTYP      100 non-null    object\n",
      " 4   MOVKEY      100 non-null    object\n",
      " 5   SRC_ITEM    100 non-null    int64 \n",
      " 6   SRC_LOT     100 non-null    int64 \n",
      " 7   SRC_QACODE  100 non-null    object\n",
      " 8   DST_LOT     100 non-null    int64 \n",
      " 9   DST_QACODE  100 non-null    object\n",
      " 10  SRC_WA      100 non-null    object\n",
      " 11  SRC_X       100 non-null    int64 \n",
      " 12  SRC_Y       100 non-null    int64 \n",
      " 13  SRC_Z       100 non-null    object\n",
      " 14  DST_WA      100 non-null    object\n",
      " 15  DST_X       100 non-null    int64 \n",
      " 16  DST_Y       100 non-null    int64 \n",
      " 17  DST_Z       100 non-null    int64 \n",
      " 18  REQQTY      100 non-null    int64 \n",
      " 19  CONQTY      100 non-null    int64 \n",
      " 20  INCNUM      100 non-null    int64 \n",
      " 21  INCLIN      100 non-null    int64 \n",
      " 22  OUTNUM      100 non-null    int64 \n",
      " 23  RELNUM      100 non-null    int64 \n",
      " 24  LISNUM      100 non-null    int64 \n",
      " 25  SUMLIS      100 non-null    int64 \n",
      " 26  TRNNUM      100 non-null    int64 \n",
      " 27  CRTDAT      100 non-null    object\n",
      " 28  TRNDAT      100 non-null    object\n",
      " 29  USERID      100 non-null    object\n",
      " 30  VOLREQ      100 non-null    int64 \n",
      " 31  VOLPIC      100 non-null    int64 \n",
      " 32  LOADDAT     100 non-null    object\n",
      "dtypes: int64(22), object(11)\n",
      "memory usage: 25.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Due to error while loading csv into parquet - data has to be cleaned, following im checking which columns have mixed types",
   "id": "f647e5f0e104e495"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:22:00.937841Z",
     "start_time": "2024-11-25T11:21:16.038058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Code to check which columns have mixed types due to error while loading csv\n",
    "import pandas as pd\n",
    "\n",
    "# Load a small chunk of the file or the whole file\n",
    "df = pd.read_csv('../Data/bewegungen.csv')\n",
    "\n",
    "# Specify the columns expected to be numeric\n",
    "numeric_columns = [\"SRC_X\", \"SRC_Y\", \"DST_X\", \"DST_Y\", \"REQQTY\", \"CONQTY\"]\n",
    "\n",
    "# Iterate through each numeric column and find non-numeric values\n",
    "for column in numeric_columns:\n",
    "    non_numeric = df[~df[column].apply(lambda x: str(x).replace('.', '', 1).isdigit())]\n",
    "    if not non_numeric.empty:\n",
    "        print(f\"Non-numeric values found in column '{column}':\")\n",
    "        print(non_numeric[[column]].head())  # Show examples of non-numeric rows\n"
   ],
   "id": "19790cba7e97903d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manu\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3553: DtypeWarning: Columns (6,8,11,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.25 GiB for an array with shape (15, 20094145) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_23468\\3942125470.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# Load a small chunk of the file or the whole file\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'../Data/bewegungen.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# Specify the columns expected to be numeric\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    486\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    487\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 488\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    489\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    490\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1057\u001B[0m             \u001B[0mnew_rows\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1058\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1059\u001B[1;33m         \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcol_dict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1060\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1061\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_currow\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mnew_rows\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    612\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    613\u001B[0m             \u001B[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 614\u001B[1;33m             \u001B[0mmgr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdict_to_mgr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtyp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmanager\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    615\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMaskedArray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    616\u001B[0m             \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmrecords\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mmrecords\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36mdict_to_mgr\u001B[1;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    464\u001B[0m     return arrays_to_mgr(\n\u001B[1;32m--> 465\u001B[1;33m         \u001B[0marrays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_names\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtyp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtyp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconsolidate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    466\u001B[0m     )\n\u001B[0;32m    467\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36marrays_to_mgr\u001B[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[0;32m    134\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mtyp\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"block\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    135\u001B[0m         return create_block_manager_from_arrays(\n\u001B[1;32m--> 136\u001B[1;33m             \u001B[0marrays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr_names\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconsolidate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconsolidate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    137\u001B[0m         )\n\u001B[0;32m    138\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mtyp\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"array\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36mcreate_block_manager_from_arrays\u001B[1;34m(arrays, names, axes, consolidate)\u001B[0m\n\u001B[0;32m   1771\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1772\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1773\u001B[1;33m         \u001B[0mblocks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_form_blocks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconsolidate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1774\u001B[0m         \u001B[0mmgr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBlockManager\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mblocks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1775\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36m_form_blocks\u001B[1;34m(arrays, names, axes, consolidate)\u001B[0m\n\u001B[0;32m   1861\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitems_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"ObjectBlock\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1862\u001B[0m         object_blocks = _simple_blockify(\n\u001B[1;32m-> 1863\u001B[1;33m             \u001B[0mitems_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"ObjectBlock\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobject_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconsolidate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconsolidate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1864\u001B[0m         )\n\u001B[0;32m   1865\u001B[0m         \u001B[0mblocks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobject_blocks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36m_simple_blockify\u001B[1;34m(tuples, dtype, consolidate)\u001B[0m\n\u001B[0;32m   1901\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_tuples_to_blocks_no_consolidate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtuples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1902\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1903\u001B[1;33m     \u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplacement\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_stack_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtuples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1904\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1905\u001B[0m     \u001B[1;31m# TODO: CHECK DTYPE?\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\PythonProject\\.venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36m_stack_arrays\u001B[1;34m(tuples, dtype)\u001B[0m\n\u001B[0;32m   1955\u001B[0m     \u001B[0mshape\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mfirst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1956\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1957\u001B[1;33m     \u001B[0mstacked\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1958\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1959\u001B[0m         \u001B[0mstacked\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 2.25 GiB for an array with shape (15, 20094145) and data type object"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Manually set dtypes, because the pandas inferred ones were not correct or unoptimized for performance.**",
   "id": "c7b8169c66700e9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cleanup bewegungen.csv -> adjust dtype and load to parquet for more efficient access\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "\n",
    "# Adjusted dtype mapping\n",
    "df_bewegungen = pd.read_csv(\n",
    "    '../Data/bewegungen.csv',\n",
    "    dtype={\n",
    "        \"MOVNUM\": \"int64\",\n",
    "        \"WORNUM\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"MOVTYP\": \"category\",\n",
    "        \"MOVKEY\": \"category\",\n",
    "        \"SRC_ITEM\": \"category\", #category ideal - unique 900k articles, repeated articles IDs, column might be used for grouping, filtering and comparisons later on\n",
    "        \"SRC_LOT\": \"category\",\n",
    "        \"SRC_QACODE\": \"category\",\n",
    "        \"DST_LOT\": \"category\",\n",
    "        \"DST_QACODE\": \"category\",\n",
    "        \"SRC_WA\": \"category\",\n",
    "        \"DST_WA\": \"category\",\n",
    "        \"SRC_X\": \"object\",\n",
    "        \"SRC_Y\": \"object\",\n",
    "        \"SRC_Z\": \"category\",\n",
    "        \"DST_X\": \"object\", #always the same destination for X,Y and Z -> Warenausgang\n",
    "        \"DST_Y\": \"object\",\n",
    "        \"DST_Z\": \"category\",\n",
    "        \"REQQTY\": \"int64\",\n",
    "        \"CONQTY\": \"int64\",\n",
    "        \"INCNUM\": \"int64\",\n",
    "        \"LISNUM\": \"int64\",\n",
    "        \"USERID\": \"category\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"],\n",
    "    chunksize=100000  # Process large files in chunks\n",
    ")\n",
    "\n",
    "# Process chunks\n",
    "for chunk in df_bewegungen:\n",
    "    print(chunk.info())\n",
    "\n",
    "# Save to Parquet\n",
    "df.to_parquet('../Data/processed_bewegungen.parquet', index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "59b74116f2efdcfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Its beginning to show that I have to clean the table and take a closer look at all columns.\n",
    "First step: Collect all unique values in SRC_LOT column"
   ],
   "id": "e82cd102ec437a3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T10:59:57.729016Z",
     "start_time": "2024-11-25T10:59:31.049621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the file in chunks\n",
    "chunk_iter = pd.read_csv(\n",
    "    '../Data/bewegungen.csv',\n",
    "    dtype={\n",
    "        \"SRC_LOT\": \"category\",  # Ensures memory efficiency for repetitive values\n",
    "    },\n",
    "    usecols=[\"SRC_LOT\"],  # Only load the SRC_LOT column\n",
    "    chunksize=100000      # Process in chunks\n",
    ")\n",
    "\n",
    "# Collect unique values from all chunks\n",
    "unique_values = set()\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    unique_values.update(chunk['SRC_LOT'].unique())\n",
    "\n",
    "# Convert the set to a sorted list and print the values\n",
    "unique_values = sorted(unique_values)\n",
    "print(\"Unique values in SRC_LOT column:\")\n",
    "print(unique_values)\n"
   ],
   "id": "9855183414076414",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in SRC_LOT column:\n",
      "['.001', '000', '001', '0016', '002', '003', '004', '005', '006', '007', '008', '009', '01', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '02', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '042', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', '054', '055', '056', '057', '058', '059', '060', '061', '062', '073', '074', '075', '077', '088', '089', '090', '091', '1', '1001', '223', 'de001', 'o001']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:17:42.831636Z",
     "start_time": "2024-11-25T11:17:41.728520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_values_count = df['SRC_LOT'].nunique()\n",
    "print(f\"Number of unique values in SRC_LOT: {unique_values_count}\")\n",
    "unique_values = df['SRC_LOT'].unique()\n",
    "print(f\"Unique values in SRC_LOT: {unique_values}\")\n"
   ],
   "id": "4aa5d467bb7b4baf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in SRC_LOT: 71\n",
      "Unique values in SRC_LOT: ['1' '11' '4' '3' '2' '7' '6' '10' '5' '19' '33' '9' '16' '20' '17' '90'\n",
      " '24' '32' '13' '8' '12' '23' '14' '21' '31' '43' '15' '55' '18' '53' '26'\n",
      " '89' '30' '28' '49' '73' '25' '39' '54' '52' '44' '60' '38' '34' '22'\n",
      " '37' '29' '36' '88' '59' '27' '42' '61' '47' '40' '75' '58' '41' '77'\n",
      " '57' '56' '45' '50' '48' '74' '46' '223' '91' '62' '35' '51']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Above output shows the issue that there is a mix of data types. Before I decide what to do with the outliers, I need to find out how these values are spread out.",
   "id": "1399f3c14a826373"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:17:02.366339Z",
     "start_time": "2024-11-25T11:16:57.448165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a function to determine the type of each entry\n",
    "def get_dtype(value):\n",
    "    return type(value).__name__\n",
    "\n",
    "# Apply the function to the SRC_LOT column and count occurrences of each type\n",
    "type_counts = df['SRC_LOT'].apply(get_dtype).value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(\"Data types in SRC_LOT column:\")\n",
    "print(type_counts)\n"
   ],
   "id": "545e072ef06cdbbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in SRC_LOT column:\n",
      "str    17931231\n",
      "Name: SRC_LOT, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I can see most Data types are int and str, I wonder what the floats are - so I output them to a .csv file for me to see",
   "id": "47c721ae8167edcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:16:16.577008Z",
     "start_time": "2024-11-25T11:16:13.567499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "output_folder = r\"H:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\Data\\temp\"\n",
    "output_file = os.path.join(output_folder, \"float_values_in_src_lot_v2.csv\")\n",
    "\n",
    "# Function to identify floats in the SRC_LOT column\n",
    "def is_float(value):\n",
    "    return isinstance(value, float)\n",
    "\n",
    "# Filter rows where SRC_LOT contains floats\n",
    "float_values = df[df['SRC_LOT'].apply(is_float)]\n",
    "\n",
    "# Select only the columns you need (SRC_LOT and SRC_ITEM)\n",
    "float_values_filtered = float_values[['SRC_LOT', 'SRC_ITEM', 'CRTDAT']]\n",
    "\n",
    "# Save the results to the specified folder\n",
    "float_values_filtered.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"CSV file with float values in SRC_LOT saved at: {output_file}\")\n"
   ],
   "id": "1cfe035a722f7307",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file with float values in SRC_LOT saved at: H:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\Data\\temp\\float_values_in_src_lot_v2.csv\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The Data all has the same CRTDate from way back in 2022 traced back to the same day. I will remove these float values as i cannot validate their correctness.\n",
    "-At the same time, I'm going to convert all values to strings for consitency before cleaning those up aswell\n",
    "-The SRC_LOT 000/0 is relevant and should should also stay in the system"
   ],
   "id": "a7b5fa9024c25cc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:21:05.911675Z",
     "start_time": "2024-11-25T11:20:46.337125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove all float values from the column\n",
    "df = df[df['SRC_LOT'].apply(lambda x: not isinstance(x, float))]\n",
    "\n",
    "# Convert all entries in the column to strings\n",
    "df['SRC_LOT'] = df['SRC_LOT'].astype(str)\n",
    "\n",
    "# Strip leading zeros but ensure \"000\" becomes \"0\"\n",
    "df['SRC_LOT'] = df['SRC_LOT'].apply(lambda x: '0' if x == '000' else x.lstrip('0'))\n",
    "\n",
    "# Validate format (numeric only and max 3 characters)\n",
    "df['SRC_LOT'] = df['SRC_LOT'].apply(lambda x: x if x.isdigit() and len(x) <= 3 else None)\n",
    "\n",
    "# Filter out rows where SRC_LOT is None (invalid entries)\n",
    "df = df[df['SRC_LOT'].notna()]\n",
    "\n",
    "# Reset index after filtering\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print cleaned column\n",
    "unique_values_count = df['SRC_LOT'].nunique()\n",
    "print(f\"Number of unique values in cleaned SRC_LOT: {unique_values_count}\")\n",
    "unique_values = df['SRC_LOT'].unique()\n",
    "print(f\"Cleaned unique values in SRC_LOT: {unique_values}\")"
   ],
   "id": "c29358face1fe92e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in cleaned SRC_LOT: 71\n",
      "Cleaned unique values in SRC_LOT: ['1' '11' '4' '3' '2' '7' '6' '10' '5' '19' '33' '9' '16' '20' '17' '90'\n",
      " '24' '32' '13' '8' '12' '23' '14' '21' '31' '43' '15' '55' '18' '53' '26'\n",
      " '89' '30' '28' '49' '73' '25' '39' '54' '52' '44' '60' '38' '34' '22'\n",
      " '37' '29' '36' '88' '59' '27' '42' '61' '47' '40' '75' '58' '41' '77'\n",
      " '57' '56' '45' '50' '48' '74' '46' '223' '91' '62' '35' '51']\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "beaa09a4dab67c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#check if null values are present\n",
    "round((df.isnull().sum()/df.shape[0])*100,2)"
   ],
   "id": "38b7e27b7f207933",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#count unique entries in each row of the table\n",
    "unique_counts = df.nunique()\n",
    "print(unique_counts)"
   ],
   "id": "fb9744e7049ee790",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5602a150fb1bb18c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Complete Mapping of all Tables of Data that I will be needing (for now).",
   "id": "a44531c71235a921"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read Bewegungen 1.1 (WMDT) - only PIC movements, otherwise the file would be too big (50gb+)\n",
    "df_bewegungen = pd.read_csv(\n",
    "    '../Data/bewegungen.csv',\n",
    "    dtype={\n",
    "        \"MOVNUM\": \"int64\",\n",
    "        \"WORNUM\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"MOVTYP\": \"category\",\n",
    "        \"MOVKEY\": \"category\",\n",
    "        \"SRC_ITEM\": \"category\", #category ideal - unique 900k articles, repeated articles IDs, column might be used for grouping, filtering and comparisons later on\n",
    "        \"SRC_LOT\": \"category\",\n",
    "        \"SRC_QACODE\": \"category\",\n",
    "        \"DST_LOT\": \"category\",\n",
    "        \"DST_QACODE\": \"category\",\n",
    "        \"SRC_WA\": \"category\",\n",
    "        \"DST_WA\": \"category\",\n",
    "        \"SRC_X\": \"object\",\n",
    "        \"SRC_Y\": \"object\",\n",
    "        \"SRC_Z\": \"category\",\n",
    "        \"DST_X\": \"object\", #always the same destination for X,Y and Z -> Warenausgang\n",
    "        \"DST_Y\": \"object\",\n",
    "        \"DST_Z\": \"category\",\n",
    "        \"REQQTY\": \"int64\",\n",
    "        \"CONQTY\": \"int64\",\n",
    "        \"INCNUM\": \"int64\",\n",
    "        \"LISNUM\": \"int64\",\n",
    "        \"USERID\": \"category\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"]\n",
    ")\n",
    "\n",
    "# Read Warenausgang Kopf 7a\n",
    "df_wa_kopf = pd.read_csv(\n",
    "    '../Data/wa_kopf.csv',\n",
    "    dtype={\n",
    "        \"OUTNUM\": \"int64\",\n",
    "        \"DOCNUM\": \"int64\",\n",
    "        \"ORDNUM\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"CUSNUM\": \"int64\",\n",
    "        \"SHPTYP\": \"category\",\n",
    "        \"TOUR\": \"int64\",\n",
    "    },\n",
    "    parse_dates=[\"ORDDAT\", \"DLVDAT\", \"CRTDAT\", \"TRNDAT\"]\n",
    ")\n",
    "\n",
    "# Read Warenausgang Positionen 7b\n",
    "df_wa_positionen = pd.read_csv(\n",
    "    '../Data/wa_positionen.csv',\n",
    "    dtype={\n",
    "        \"OUTNUM\": \"int64\",\n",
    "        \"OUTLIN\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"ITEM\": \"int64\",\n",
    "        \"LOT\": \"category\",\n",
    "        \"QACODE\": \"category\",\n",
    "        \"ORDQTY\": \"int64\",\n",
    "        \"RELQTY\": \"int64\",\n",
    "        \"FNDQTY\": \"int64\",\n",
    "        \"CONQTY\": \"int64\",\n",
    "        \"SHPQTY\": \"int64\",\n",
    "        \"USERID\": \"category\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"]\n",
    ")\n",
    "\n",
    "# Read Listen 8\n",
    "df_listen = pd.read_csv(\n",
    "    '../Data/listen.csv',\n",
    "    dtype={\n",
    "        \"LISNUM\": \"int64\",\n",
    "        \"SUMLIS\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"PRIO\": \"int64\",\n",
    "        \"PZ\": \"category\",\n",
    "        \"RELNUM\": \"int64\",\n",
    "        \"CUSNUM\": \"int64\",\n",
    "        \"DSPADR\": \"category\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"]\n",
    ")\n",
    "\n",
    "# Read Artikelbestand 5\n",
    "df_artikelbestand = pd.read_csv(\n",
    "    '../Data/artikelbestand.csv',\n",
    "    dtype={\n",
    "        \"OBJNUM\": \"int64\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"LOCNUM\": \"int64\",\n",
    "        \"PICLCK\": \"bool\",\n",
    "        \"STTLCK\": \"bool\",\n",
    "        \"ITEM\": \"int64\",\n",
    "        \"LOT\": \"category\",\n",
    "        \"INQTY\": \"int64\",\n",
    "        \"OUTQTY\": \"int64\",\n",
    "        \"AVLQTY\": \"int64\",\n",
    "        \"CONQTY\": \"int64\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"]\n",
    ")\n",
    "\n",
    "# Read Lagerplatz 3\n",
    "df_lagerplatz = pd.read_csv(\n",
    "    '../Data/lagerplatz.csv',\n",
    "    dtype={\n",
    "        \"OBJNUM\": \"int64\",\n",
    "        \"WH\": \"category\",\n",
    "        \"WA\": \"category\",\n",
    "        \"X\": \"int64\",\n",
    "        \"Y\": \"int64\",\n",
    "        \"Z\": \"object\",\n",
    "        \"STATUS\": \"category\",\n",
    "        \"PUTPRI\": \"int64\",\n",
    "        \"PICPRI\": \"int64\",\n",
    "    },\n",
    "    parse_dates=[\"CRTDAT\", \"TRNDAT\"]\n",
    ")\n"
   ],
   "id": "f373e4dfb0042eec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display info for Bewegungen 1.1 (WMDT)\n",
    "print(\"Bewegungen 1.1 Info:\")\n",
    "print(df_bewegungen.info())\n",
    "\n",
    "# Display info for Warenausgang Kopf 7a\n",
    "print(\"\\nWarenausgang Kopf Info:\")\n",
    "print(df_wa_kopf.info())\n",
    "\n",
    "# Display info for Warenausgang Positionen 7b\n",
    "print(\"\\nWarenausgang Positionen Info:\")\n",
    "print(df_wa_positionen.info())\n",
    "\n",
    "# Display info for Listen 8\n",
    "print(\"\\nListen Info:\")\n",
    "print(df_listen.info())\n",
    "\n",
    "# Display info for Artikelbestand 5\n",
    "print(\"\\nArtikelbestand Info:\")\n",
    "print(df_artikelbestand.info())\n",
    "\n",
    "# Display info for Lagerplatz 3\n",
    "print(\"\\nLagerplatz Info:\")\n",
    "print(df_lagerplatz.info())\n"
   ],
   "id": "978727dd8db69317",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
