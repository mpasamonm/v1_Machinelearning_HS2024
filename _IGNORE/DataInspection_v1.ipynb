{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "load prepared parquet",
   "id": "98fb10965e793275"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "# reading parquet file later\n",
    "\n",
    "df_loaded = pd.read_parquet('joined_data_v1.parquet')\n",
    "print(df_loaded.head())"
   ],
   "id": "64a1b4efa183b22d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "understand structure",
   "id": "a802028c81046183"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df_loaded.info())  # Overview of columns and data types\n",
    "print(df_loaded.describe())  # Summary statistics for numerical columns\n",
    "print(df_loaded.head())  # Preview the first few rows\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "check missing data",
   "id": "a60b17013638e07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(df_loaded.isna().sum())  # Count missing values in each column\n",
   "id": "b309cfb3886c6b5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "visualize distributions",
   "id": "7428c4063680f636"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_loaded.hist(figsize=(12, 8))  # Histogram for numerical columns\n",
   "id": "aac238ad64c3fab6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "identifiy duplicates",
   "id": "152782d51b01ef4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(df_loaded.duplicated().sum())  # Count duplicated rows\n",
   "id": "27214652d7024587"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature engineering -- categorical data needs to be encoded",
   "id": "838fed761bf8db7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "dd664d013f9c517a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"data.csv\"  # Adjust to your actual file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=[\"\"], inplace=True)\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = [\n",
    "    \"STATUS_x\", \"SRC_QACODE\", \"DST_QACODE\", \"SRC_WA\", \"DST_WA\", \"USERID_x\", \"STATUS_y\", \"PICCOD\", \"SHPTYP\", \"USERID_y\"\n",
    "]\n",
    "\n",
    "# Low cardinality: Use One-Hot Encoding\n",
    "low_cardinality_cols = [col for col in categorical_cols if df[col].nunique() < 10]\n",
    "df = pd.get_dummies(df, columns=low_cardinality_cols, drop_first=True)\n",
    "\n",
    "# High cardinality: Use Label Encoding\n",
    "high_cardinality_cols = [col for col in categorical_cols if col not in low_cardinality_cols]\n",
    "label_encoders = {}\n",
    "for col in high_cardinality_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le  # Save encoder for future use\n",
    "\n",
    "# Handle date columns\n",
    "date_cols = [\"CRTDAT_x\", \"TRNDAT_x\", \"LOADDAT_x\", \"CRTDAT_y\", \"TRNDAT_y\", \"LOADDAT_y\", \"CRTDAT\", \"TRNDAT\", \"LOADDAT\"]\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], errors=\"coerce\")  # Convert to datetime\n",
    "    df[f\"{col}_year\"] = df[col].dt.year\n",
    "    df[f\"{col}_month\"] = df[col].dt.month\n",
    "    df[f\"{col}_day\"] = df[col].dt.day\n",
    "    df[f\"{col}_weekday\"] = df[col].dt.weekday\n",
    "    df[f\"{col}_hour\"] = df[col].dt.hour\n",
    "    df.drop(columns=[col], inplace=True)  # Drop original date column after feature extraction\n",
    "\n",
    "# Normalize numerical columns if needed\n",
    "numerical_cols = [\n",
    "    \"WORNUM\", \"OUTNUM\", \"LISNUM\", \"SUMLIS\", \"TRNNUM_x\", \"TRNNUM_y\", \"OUTLIN\", \"ORDQTY\", \"RELQTY\", \"FNDQTY\", \"CONQTY\", \"SHPQTY\"\n",
    "]\n",
    "df[numerical_cols] = df[numerical_cols].fillna(0)  # Fill missing values\n",
    "df[numerical_cols] = (df[numerical_cols] - df[numerical_cols].mean()) / df[numerical_cols].std()  # Standardize\n",
    "\n"
   ],
   "id": "a342d7739d49ea9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the processed DataFrame to a new file\n",
    "processed_file = \"processed_data.parquet\"\n",
    "df.to_parquet(processed_file, index=False)\n",
    "\n",
    "print(f\"Processed data saved to {processed_file}\")"
   ],
   "id": "5d95e081d48326c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
