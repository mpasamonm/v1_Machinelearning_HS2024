{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### All copied from final_dataprep_v1.ipynb to testrun fully and merge the df on FK and PKs for first usecase",
   "id": "79950e80aaecd0be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bewegungen.csv prep",
   "id": "52a6ed4c6ae38002"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c635ace25537efef"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-31T12:50:16.311636Z",
     "start_time": "2024-12-31T12:48:55.494288Z"
    }
   },
   "source": [
    "# consolidated :::\n",
    "import pandas as pd\n",
    "from idna.idnadata import joining_types\n",
    "\n",
    "# List of columns to keep (ran into memory issues...)\n",
    "columns_to_keep = [\n",
    "    \"STATUS\", \"SRC_ITEM\", \"SRC_LOT\", \"SRC_QACODE\",\n",
    "    \"DST_QACODE\", \"SRC_WA\", \"SRC_X\", \"SRC_Y\", \"SRC_Z\", \"CONQTY\", \"OUTNUM\",\n",
    "    \"LISNUM\", \"SUMLIS\", \"TRNDAT\", \"USERID\", # , \"TRNNUM\", \"WORNUM\", \"DST_LOT\", \"DST_WA\", \"LOADDAT\", \"CRTDAT\" not needed (just the date when its imported into DWH)\n",
    "]\n",
    "\n",
    "dtypes = {\n",
    "#    \"WORNUM\": \"int32\",\n",
    "    \"STATUS\": \"int32\",\n",
    "#    \"MOVTYP\": \"category\",\n",
    "#    \"MOVKEY\": \"category\",\n",
    "    \"SRC_ITEM\": \"category\",\n",
    "    \"SRC_LOT\": \"string\",\n",
    "    \"SRC_QACODE\": \"category\",\n",
    "    #\"DST_LOT\": \"string\",\n",
    "    \"DST_QACODE\": \"category\",\n",
    "    \"SRC_WA\": \"category\",\n",
    "    \"SRC_X\": \"category\",\n",
    "    \"SRC_Y\": \"category\",\n",
    "    \"SRC_Z\": \"category\",\n",
    "#    \"DST_WA\": \"category\",\n",
    "    \"CONQTY\": \"int32\",\n",
    "    \"OUTNUM\": \"int32\", # KEY\n",
    "#    \"RELNUM\": \"int32\",\n",
    "    \"LISNUM\": \"int32\",\n",
    "    \"SUMLIS\": \"int32\",\n",
    "#    \"TRNNUM\": \"int32\",\n",
    "    \"USERID\": \"category\",\n",
    "}\n",
    "\n",
    "# Load the CSV with optimized settings, and only load necessary cols\n",
    "df_bewegungen = pd.read_csv(\n",
    "    '../Data/bewegungen.csv',\n",
    "    usecols=columns_to_keep,  # Only load the specified columns\n",
    "    dtype=dtypes, # use optimized, manually set data types\n",
    "    #usecols=columns_to_use,  # Only load required columns\n",
    "    parse_dates=[\"TRNDAT\"],\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Clean SRC_LOT column (Column \"Artikelcharge\", this LOT usually is a 3 digit int. An Article can have multiple LOTs. I simplify by removing leading zeros and clean up the column from wrong manual usererrors.\n",
    "#df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].fillna('').astype(str)  # Handle NaNs and convert to string\n",
    "#df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].apply(lambda x: '0' if x == '000' else x.lstrip('0'))  # Remove leading zeros\n",
    "#df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].apply(lambda x: x if x.isdigit() and len(x) <= 3 else None)  # Validate format\n",
    "# keep value if: consists of digits, and its length is less than or equal to 3 -- otherwise replace with none\n",
    "\n",
    "# Clean DST_LOT column\n",
    "#df_bewegungen['DST_LOT'] = df_bewegungen['DST_LOT'].fillna('').astype(str)  # Handle NaNs and convert to string\n",
    "#df_bewegungen['DST_LOT'] = df_bewegungen['DST_LOT'].apply(lambda x: '0' if x == '000' else x.lstrip('0'))  # Remove leading zeros\n",
    "#df_bewegungen['DST_LOT'] = df_bewegungen['DST_LOT'].apply(lambda x: x if x.isdigit() and len(x) <= 3 else None)  # Validate format\n",
    "# keep value if: consists of digits, and its length is less than or equal to 3 -- otherwise replace with none\n",
    "\n",
    "####\n",
    "# Data Cleaning\n",
    "####\n",
    "\n",
    "# Temporarily convert 'SRC_LOT' to string type for cleaning\n",
    "df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].astype(str)  # Convert Categorical to string\n",
    "\n",
    "# Clean and validate the SRC_LOT column (Column \"Artikelcharge\", this LOT usually is a 3 digit int. An Article can have multiple LOTs. I simplify by removing leading zeros and clean up the column from wrong manual usererrors.)\n",
    "def clean_lot(value):\n",
    "    value = value.lstrip('0') if value != '000' else value  # Remove leading zeros unless '000'\n",
    "    if value.isdigit() and 1 <= len(value) <= 3:           # Validate length (1 to 3 digits)\n",
    "        return value.zfill(3)                              # Pad with leading zeros to ensure 3 digits\n",
    "    return None                                            # Remove invalid entries\n",
    "\n",
    "df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].apply(clean_lot)\n",
    "# Convert back to Categorical if needed\n",
    "df_bewegungen['SRC_LOT'] = pd.Categorical(df_bewegungen['SRC_LOT'])\n",
    "\n",
    "# Clean STATUS column (10= Offen, 50= Bestätigt, 95= Storniert -- for my purposes I'm only interested in \"Bestätigt\" rows.\n",
    "# Filter the DataFrame to keep only rows with status == 50 (abgeschlossen)\n",
    "df_bewegungen = df_bewegungen[df_bewegungen['STATUS'] == 50]\n",
    "\n",
    "# Filter the DataFrame in place to include only rows where 'SRC_WA' contains \"WA\", excluding all 'WE', 'WA', 'AU' and 'UM' areas\n",
    "df_bewegungen = df_bewegungen[df_bewegungen['SRC_WA'] == 'EG']\n",
    "\n",
    "# Remove rows where USER == 'LXONE'\n",
    "df_bewegungen = df_bewegungen[df_bewegungen['USERID'] != 'LXONE']\n",
    "\n",
    "# Only keep rows with QACODE == 'H'\n",
    "df_bewegungen = df_bewegungen[df_bewegungen['SRC_QACODE'] == 'H']\n",
    "\n",
    "# Remove all additional Crossdocking movements, easiest to pinpoint via SRC_LOT = 000\n",
    "df_bewegungen = df_bewegungen[df_bewegungen['SRC_LOT'] != '000']\n",
    "\n",
    "\n",
    "# Combine SRC_X, SRC_Y, and SRC_Z into a new column STOR_LOC\n",
    "df_bewegungen['STOR_LOC'] = df_bewegungen['SRC_X'].astype(str) + \\\n",
    "                            df_bewegungen['SRC_Y'].astype(str) + \\\n",
    "                            df_bewegungen['SRC_Z'].astype(str)\n",
    "\n",
    "# Change datatypes as needed\n",
    "df_bewegungen = df_bewegungen.astype({\n",
    "    \"SRC_LOT\": \"category\",\n",
    "#    \"DST_LOT\": \"category\",\n",
    "    \"STOR_LOC\": \"category\",\n",
    "})\n",
    "\n",
    "# Drop the original SRC_X, SRC_Y, and SRC_Z columns\n",
    "df_bewegungen.drop(['SRC_X', 'SRC_Y', 'SRC_Z'], axis=1, inplace=True)\n",
    "\n",
    "# Drop rows with missing values from the DataFrame - dropna (by default, without parameters) removes entire rows which have a NaN or null value\n",
    "df_bewegungen.dropna(inplace=True)\n",
    "\n",
    "# Drop both 'SRC_WA' and 'DST_WA' columns from the DataFrame now that we filtered the data\n",
    "df_bewegungen.drop(columns=['STATUS', 'SRC_WA', 'SRC_QACODE', 'DST_QACODE'], inplace=True)\n",
    "\n",
    "# Remove unused categories (i.e. Artifacts) across all categorical columns (after all cleaning steps there were pandas retained all defined categories, even though they no longer existed in the data. Not sure if this would've led to problems down the road during embedding/labeling, so I removed them to avoid eventual issues)\n",
    "for col in df_bewegungen.select_dtypes(include='category').columns:\n",
    "    df_bewegungen[col] = df_bewegungen[col].cat.remove_unused_categories()\n",
    "\n",
    "# Verify the changes\n",
    "print(f\"Updated DataFrame shape: {df_bewegungen.shape}\")\n",
    "# :::"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 37\u001B[0m\n\u001B[0;32m     12\u001B[0m dtypes \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m#    \"WORNUM\": \"int32\",\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSTATUS\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mint32\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSERID\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcategory\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     34\u001B[0m }\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# Load the CSV with optimized settings, and only load necessary cols\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m df_bewegungen \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../Data/bewegungen.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns_to_keep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Only load the specified columns\u001B[39;49;00m\n\u001B[0;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# use optimized, manually set data types\u001B[39;49;00m\n\u001B[0;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#usecols=columns_to_use,  # Only load required columns\u001B[39;49;00m\n\u001B[0;32m     42\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTRNDAT\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlow_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m     44\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Clean SRC_LOT column (Column \"Artikelcharge\", this LOT usually is a 3 digit int. An Article can have multiple LOTs. I simplify by removing leading zeros and clean up the column from wrong manual usererrors.\u001B[39;00m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m#df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].fillna('').astype(str)  # Handle NaNs and convert to string\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m#df_bewegungen['SRC_LOT'] = df_bewegungen['SRC_LOT'].apply(lambda x: '0' if x == '000' else x.lstrip('0'))  # Remove leading zeros\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     61\u001B[0m \n\u001B[0;32m     62\u001B[0m \u001B[38;5;66;03m# Temporarily convert 'SRC_LOT' to string type for cleaning\u001B[39;00m\n\u001B[0;32m     63\u001B[0m df_bewegungen[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSRC_LOT\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_bewegungen[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSRC_LOT\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mstr\u001B[39m)  \u001B[38;5;66;03m# Convert Categorical to string\u001B[39;00m\n",
      "File \u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[1;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[0;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[0;32m   1919\u001B[0m     (\n\u001B[0;32m   1920\u001B[0m         index,\n\u001B[0;32m   1921\u001B[0m         columns,\n\u001B[0;32m   1922\u001B[0m         col_dict,\n\u001B[1;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[0;32m   1924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[0;32m   1925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:332\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    328\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_data_length(names, alldata)\n\u001B[0;32m    330\u001B[0m     data \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, (i, v) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(names, data_tups)}\n\u001B[1;32m--> 332\u001B[0m     names, date_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_date_conversions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    333\u001B[0m     index, column_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_index(date_data, alldata, names)\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m index, column_names, date_data\n",
      "File \u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:880\u001B[0m, in \u001B[0;36mParserBase._do_date_conversions\u001B[1;34m(self, names, data)\u001B[0m\n\u001B[0;32m    871\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[0;32m    872\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_do_date_conversions\u001B[39m(\n\u001B[0;32m    873\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    876\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[Sequence[Hashable] \u001B[38;5;241m|\u001B[39m Index, Mapping[Hashable, ArrayLike] \u001B[38;5;241m|\u001B[39m DataFrame]:\n\u001B[0;32m    877\u001B[0m     \u001B[38;5;66;03m# returns data, columns\u001B[39;00m\n\u001B[0;32m    879\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparse_dates \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 880\u001B[0m         data, names \u001B[38;5;241m=\u001B[39m \u001B[43m_process_date_conversion\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_date_conv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    883\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    884\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    885\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    886\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    887\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_date_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeep_date_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    888\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    889\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    891\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m names, data\n",
      "File \u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:1315\u001B[0m, in \u001B[0;36m_process_date_conversion\u001B[1;34m(data_dict, converter, parse_spec, index_col, index_names, columns, keep_date_col, dtype_backend)\u001B[0m\n\u001B[0;32m   1311\u001B[0m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1313\u001B[0m     \u001B[38;5;66;03m# Pyarrow engine returns Series which we need to convert to\u001B[39;00m\n\u001B[0;32m   1314\u001B[0m     \u001B[38;5;66;03m# numpy array before converter, its a no-op for other parsers\u001B[39;00m\n\u001B[1;32m-> 1315\u001B[0m     data_dict[colspec] \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolspec\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolspec\u001B[49m\n\u001B[0;32m   1317\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1318\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1319\u001B[0m     new_name, col, old_names \u001B[38;5;241m=\u001B[39m _try_convert_dates(\n\u001B[0;32m   1320\u001B[0m         converter, colspec, data_dict, orig_names\n\u001B[0;32m   1321\u001B[0m     )\n",
      "File \u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:1165\u001B[0m, in \u001B[0;36m_make_date_converter.<locals>.converter\u001B[1;34m(col, *date_cols)\u001B[0m\n\u001B[0;32m   1163\u001B[0m str_objs \u001B[38;5;241m=\u001B[39m ensure_object(strs)\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1165\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtools\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_datetime\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1166\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstr_objs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1167\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_fmt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1168\u001B[0m \u001B[43m        \u001B[49m\u001B[43mutc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1169\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdayfirst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdayfirst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1170\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1171\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1172\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[0;32m   1173\u001B[0m     \u001B[38;5;66;03m# test_usecols_with_parse_dates4\u001B[39;00m\n\u001B[0;32m   1174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m str_objs\n",
      "File \u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1099\u001B[0m, in \u001B[0;36mto_datetime\u001B[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001B[0m\n\u001B[0;32m   1097\u001B[0m         result \u001B[38;5;241m=\u001B[39m _convert_and_box_cache(argc, cache_array)\n\u001B[0;32m   1098\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1099\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_listlike\u001B[49m\u001B[43m(\u001B[49m\u001B[43margc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1101\u001B[0m     result \u001B[38;5;241m=\u001B[39m convert_listlike(np\u001B[38;5;241m.\u001B[39marray([arg]), \u001B[38;5;28mformat\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001B[0m, in \u001B[0;36m_convert_listlike_datetimes\u001B[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001B[0m\n\u001B[0;32m    431\u001B[0m \u001B[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001B[39;00m\n\u001B[0;32m    432\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mformat\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mformat\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmixed\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_array_strptime_with_fallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mutc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexact\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    435\u001B[0m result, tz_parsed \u001B[38;5;241m=\u001B[39m objects_to_datetime64(\n\u001B[0;32m    436\u001B[0m     arg,\n\u001B[0;32m    437\u001B[0m     dayfirst\u001B[38;5;241m=\u001B[39mdayfirst,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    441\u001B[0m     allow_object\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    442\u001B[0m )\n\u001B[0;32m    444\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tz_parsed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    445\u001B[0m     \u001B[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001B[39;00m\n\u001B[0;32m    446\u001B[0m     \u001B[38;5;66;03m# is in UTC\u001B[39;00m\n",
      "File \u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:479\u001B[0m, in \u001B[0;36m_array_strptime_with_fallback\u001B[1;34m(arg, name, utc, fmt, exact, errors)\u001B[0m\n\u001B[0;32m    477\u001B[0m     res \u001B[38;5;241m=\u001B[39m Index(result, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mM8[\u001B[39m\u001B[38;5;132;01m{\u001B[39;00munit\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, UTC]\u001B[39m\u001B[38;5;124m\"\u001B[39m, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\u001B[1;32m--> 479\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mIndex\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:475\u001B[0m, in \u001B[0;36mIndex.__new__\u001B[1;34m(cls, data, dtype, copy, name, tupleize_cols)\u001B[0m\n\u001B[0;32m    470\u001B[0m _references \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    472\u001B[0m \u001B[38;5;66;03m# --------------------------------------------------------------------\u001B[39;00m\n\u001B[0;32m    473\u001B[0m \u001B[38;5;66;03m# Constructors\u001B[39;00m\n\u001B[1;32m--> 475\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__new__\u001B[39m(\n\u001B[0;32m    476\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m    477\u001B[0m     data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    478\u001B[0m     dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    479\u001B[0m     copy: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    480\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    481\u001B[0m     tupleize_cols: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    482\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mindexes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrange\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RangeIndex\n\u001B[0;32m    485\u001B[0m     name \u001B[38;5;241m=\u001B[39m maybe_extract_name(name, data, \u001B[38;5;28mcls\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:52:51.771894Z",
     "start_time": "2024-12-29T13:52:51.744870Z"
    }
   },
   "cell_type": "code",
   "source": "df_bewegungen.head()",
   "id": "96007772c6c0845d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   SRC_ITEM SRC_LOT DST_QACODE    OUTNUM     LISNUM     SUMLIS     TRNNUM  \\\n",
       "0  36529803     001          H  31313376  289679194  289679311  599324284   \n",
       "1  44118619     001          H  31320349  289874022  289874463  599670338   \n",
       "2  13091411     001          H  31324968  289835037  289835121  599596179   \n",
       "4  16359571     001          H  31346782  289840157  289725531  599576127   \n",
       "5  38789620     001          H  31344732  289808077  289726826  599529006   \n",
       "\n",
       "               TRNDAT   USERID    STOR_LOC  \n",
       "0 2024-04-25 08:16:39    24769   160102D15  \n",
       "1 2024-04-25 19:29:47   178141   178002E03  \n",
       "2 2024-04-25 16:42:37  LAESSIG   221504F13  \n",
       "4 2024-04-25 16:03:15   104044   200407G05  \n",
       "5 2024-04-25 14:44:06   170056  011208BA05  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC_ITEM</th>\n",
       "      <th>SRC_LOT</th>\n",
       "      <th>DST_QACODE</th>\n",
       "      <th>OUTNUM</th>\n",
       "      <th>LISNUM</th>\n",
       "      <th>SUMLIS</th>\n",
       "      <th>TRNNUM</th>\n",
       "      <th>TRNDAT</th>\n",
       "      <th>USERID</th>\n",
       "      <th>STOR_LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36529803</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>31313376</td>\n",
       "      <td>289679194</td>\n",
       "      <td>289679311</td>\n",
       "      <td>599324284</td>\n",
       "      <td>2024-04-25 08:16:39</td>\n",
       "      <td>24769</td>\n",
       "      <td>160102D15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44118619</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>31320349</td>\n",
       "      <td>289874022</td>\n",
       "      <td>289874463</td>\n",
       "      <td>599670338</td>\n",
       "      <td>2024-04-25 19:29:47</td>\n",
       "      <td>178141</td>\n",
       "      <td>178002E03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13091411</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>31324968</td>\n",
       "      <td>289835037</td>\n",
       "      <td>289835121</td>\n",
       "      <td>599596179</td>\n",
       "      <td>2024-04-25 16:42:37</td>\n",
       "      <td>LAESSIG</td>\n",
       "      <td>221504F13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16359571</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>31346782</td>\n",
       "      <td>289840157</td>\n",
       "      <td>289725531</td>\n",
       "      <td>599576127</td>\n",
       "      <td>2024-04-25 16:03:15</td>\n",
       "      <td>104044</td>\n",
       "      <td>200407G05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38789620</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>31344732</td>\n",
       "      <td>289808077</td>\n",
       "      <td>289726826</td>\n",
       "      <td>599529006</td>\n",
       "      <td>2024-04-25 14:44:06</td>\n",
       "      <td>170056</td>\n",
       "      <td>011208BA05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T10:37:34.157700Z",
     "start_time": "2024-12-28T10:37:32.584884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Find all categorical columns with unused categories\n",
    "for col in df_bewegungen.select_dtypes(include='category').columns:\n",
    "    unused_categories = set(df_bewegungen[col].cat.categories) - set(df_bewegungen[col].dropna().unique())\n",
    "    if unused_categories:\n",
    "        print(f\"Column '{col}' has unused categories: {unused_categories}\")\n",
    "    else:\n",
    "        print(f\"Column '{col}' has no unused categories.\")"
   ],
   "id": "203ce0af9d9d428c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'SRC_ITEM' has no unused categories.\n",
      "Column 'SRC_LOT' has no unused categories.\n",
      "Column 'DST_QACODE' has no unused categories.\n",
      "Column 'SRC_X' has no unused categories.\n",
      "Column 'SRC_Y' has no unused categories.\n",
      "Column 'SRC_Z' has no unused categories.\n",
      "Column 'USERID' has no unused categories.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:31:08.950364Z",
     "start_time": "2024-12-27T22:31:08.748721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in SRC_WA\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_bewegungen['SRC_LOT'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_bewegungen['SRC_LOT'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'DST_WA' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)\n"
   ],
   "id": "f125ad4cef096d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 71 unique entries in the 'DST_WA' column.\n",
      "\n",
      "Occurrences of each unique entry:\n",
      "001    15984112\n",
      "002      749870\n",
      "003      362855\n",
      "004      226203\n",
      "005      138548\n",
      "         ...   \n",
      "045          57\n",
      "077          50\n",
      "035          38\n",
      "051          13\n",
      "223           1\n",
      "Name: SRC_LOT, Length: 71, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:12:57.193467Z",
     "start_time": "2024-12-27T22:12:57.178324Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"000\" in df_bewegungen['SRC_LOT'].cat.categories)",
   "id": "3af195f8fba0b983",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T19:37:11.181730Z",
     "start_time": "2024-12-27T19:37:11.136789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in STATUS\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_bewegungen['SRC_QACODE'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_bewegungen['SRC_QACODE'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'SRC_QACODE' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)"
   ],
   "id": "cf3e08e49d99c95a",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SRC_QACODE'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3360\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3361\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'SRC_QACODE'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_5060\\618816945.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m####\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# Count the number of unique entries in the 'SRC_WA' column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0munique_entries_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_bewegungen\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'SRC_QACODE'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnunique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# Count the occurrences of each unique entry in the 'SRC_WA' column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3456\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3457\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3458\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3459\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3460\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3361\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3363\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3364\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3365\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'SRC_QACODE'"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T19:37:35.917355Z",
     "start_time": "2024-12-27T19:37:35.887328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in SRC_QACODE\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_bewegungen['DST_LOT'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_bewegungen['DST_LOT'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'SRC_QACODE' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)"
   ],
   "id": "407bddc4286bd05f",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DST_LOT'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3360\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3361\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'DST_LOT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_5060\\4242034765.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m####\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# Count the number of unique entries in the 'SRC_WA' column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0munique_entries_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_bewegungen\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'DST_LOT'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnunique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# Count the occurrences of each unique entry in the 'SRC_WA' column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3456\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3457\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3458\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3459\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3460\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3361\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3363\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3364\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3365\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'DST_LOT'"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:40:52.853569Z",
     "start_time": "2024-12-28T11:40:52.840558Z"
    }
   },
   "cell_type": "code",
   "source": "df_bewegungen.info()",
   "id": "df58e6095e1a7863",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17914909 entries, 0 to 20094144\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Dtype         \n",
      "---  ------      -----         \n",
      " 0   SRC_ITEM    category      \n",
      " 1   SRC_LOT     category      \n",
      " 2   DST_QACODE  category      \n",
      " 3   SRC_X       category      \n",
      " 4   SRC_Y       category      \n",
      " 5   SRC_Z       category      \n",
      " 6   OUTNUM      int32         \n",
      " 7   LISNUM      int32         \n",
      " 8   SUMLIS      int32         \n",
      " 9   TRNNUM      int32         \n",
      " 10  TRNDAT      datetime64[ns]\n",
      " 11  USERID      category      \n",
      "dtypes: category(7), datetime64[ns](1), int32(4)\n",
      "memory usage: 772.7 MB\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T10:37:57.098196Z",
     "start_time": "2024-12-28T10:37:57.074174Z"
    }
   },
   "cell_type": "code",
   "source": "df_bewegungen.head()",
   "id": "411ad1880fd30d99",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   SRC_ITEM SRC_LOT DST_QACODE SRC_X SRC_Y SRC_Z    OUTNUM     LISNUM  \\\n",
       "0  36529803     001          H  1601    02   D15  31313376  289679194   \n",
       "1  44118619     001          H  1780    02   E03  31320349  289874022   \n",
       "2  13091411     001          H  2215    04   F13  31324968  289835037   \n",
       "4  16359571     001          H  2004    07   G05  31346782  289840157   \n",
       "5  38789620     001          H  0112    08  BA05  31344732  289808077   \n",
       "\n",
       "      SUMLIS     TRNNUM              TRNDAT   USERID  \n",
       "0  289679311  599324284 2024-04-25 08:16:39    24769  \n",
       "1  289874463  599670338 2024-04-25 19:29:47   178141  \n",
       "2  289835121  599596179 2024-04-25 16:42:37  LAESSIG  \n",
       "4  289725531  599576127 2024-04-25 16:03:15   104044  \n",
       "5  289726826  599529006 2024-04-25 14:44:06   170056  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRC_ITEM</th>\n",
       "      <th>SRC_LOT</th>\n",
       "      <th>DST_QACODE</th>\n",
       "      <th>SRC_X</th>\n",
       "      <th>SRC_Y</th>\n",
       "      <th>SRC_Z</th>\n",
       "      <th>OUTNUM</th>\n",
       "      <th>LISNUM</th>\n",
       "      <th>SUMLIS</th>\n",
       "      <th>TRNNUM</th>\n",
       "      <th>TRNDAT</th>\n",
       "      <th>USERID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36529803</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>1601</td>\n",
       "      <td>02</td>\n",
       "      <td>D15</td>\n",
       "      <td>31313376</td>\n",
       "      <td>289679194</td>\n",
       "      <td>289679311</td>\n",
       "      <td>599324284</td>\n",
       "      <td>2024-04-25 08:16:39</td>\n",
       "      <td>24769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44118619</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>1780</td>\n",
       "      <td>02</td>\n",
       "      <td>E03</td>\n",
       "      <td>31320349</td>\n",
       "      <td>289874022</td>\n",
       "      <td>289874463</td>\n",
       "      <td>599670338</td>\n",
       "      <td>2024-04-25 19:29:47</td>\n",
       "      <td>178141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13091411</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>2215</td>\n",
       "      <td>04</td>\n",
       "      <td>F13</td>\n",
       "      <td>31324968</td>\n",
       "      <td>289835037</td>\n",
       "      <td>289835121</td>\n",
       "      <td>599596179</td>\n",
       "      <td>2024-04-25 16:42:37</td>\n",
       "      <td>LAESSIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16359571</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>2004</td>\n",
       "      <td>07</td>\n",
       "      <td>G05</td>\n",
       "      <td>31346782</td>\n",
       "      <td>289840157</td>\n",
       "      <td>289725531</td>\n",
       "      <td>599576127</td>\n",
       "      <td>2024-04-25 16:03:15</td>\n",
       "      <td>104044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38789620</td>\n",
       "      <td>001</td>\n",
       "      <td>H</td>\n",
       "      <td>0112</td>\n",
       "      <td>08</td>\n",
       "      <td>BA05</td>\n",
       "      <td>31344732</td>\n",
       "      <td>289808077</td>\n",
       "      <td>289726826</td>\n",
       "      <td>599529006</td>\n",
       "      <td>2024-04-25 14:44:06</td>\n",
       "      <td>170056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T10:38:48.678100Z",
     "start_time": "2024-12-28T10:38:48.183652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if the OUTNUM column in df_bewegungen has unique values\n",
    "is_unique = not df_bewegungen['OUTNUM'].duplicated().any()\n",
    "\n",
    "# Print result\n",
    "if is_unique:\n",
    "    print(\"The OUTNUM column has only unique values.\")\n",
    "else:\n",
    "    print(\"The OUTNUM column contains duplicate values.\")"
   ],
   "id": "b9a3bb249382adb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OUTNUM column contains duplicate values.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T10:39:21.110085Z",
     "start_time": "2024-12-28T10:39:20.601175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count duplicate values in the OUTNUM column\n",
    "num_duplicates = df_bewegungen['OUTNUM'].duplicated().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of duplicate values in the OUTNUM column: {num_duplicates}\")\n"
   ],
   "id": "a317ce46215fe65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate values in the OUTNUM column: 315324\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T10:40:29.214067Z",
     "start_time": "2024-12-28T10:40:28.533730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Filter rows with duplicate values in the OUTNUM column\n",
    "duplicate_rows = df_bewegungen[df_bewegungen['OUTNUM'].duplicated(keep=False)]\n",
    "\n",
    "# Retrieve the first 10 rows with duplicates\n",
    "top_10_duplicates = duplicate_rows.head(10)\n",
    "\n",
    "# Print the first 10 duplicate rows\n",
    "print(\"First 10 rows with duplicate values in the OUTNUM column:\")\n",
    "print(top_10_duplicates)"
   ],
   "id": "a8ff23d446c25f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows with duplicate values in the OUTNUM column:\n",
      "    SRC_ITEM SRC_LOT DST_QACODE SRC_X SRC_Y SRC_Z    OUTNUM     LISNUM  \\\n",
      "26  44492423     001          H  0215    01   B15  31343207  289789855   \n",
      "34  38577015     001          H  0915    04   C06  31269284  289698865   \n",
      "44  38577015     001          H  1418    10   C10  31269284  289698921   \n",
      "49  38577090     001          H  1321    13   B17  31269302  289698898   \n",
      "50  44123844     001          H  1502    06   D01  31269381  289698927   \n",
      "69  38577029     001          H  1920    13   D02  31269287  289698945   \n",
      "77  42421817     001          H  0910    02   C05  31269340  289698863   \n",
      "83  38577099     001          H  0922    11   B13  31269303  289698869   \n",
      "94  37726813     001          H  1111    11   C07  31269249  289698884   \n",
      "96  42421430     001          H  1008    15   C03  31269323  289698876   \n",
      "\n",
      "       SUMLIS     TRNNUM              TRNDAT  USERID  \n",
      "26  289789898  599583371 2024-04-25 16:24:13  152420  \n",
      "34  289698987  599602290 2024-04-25 16:49:18  157242  \n",
      "44  289699004  599360598 2024-04-25 09:29:01  165481  \n",
      "49  289699035  599328843 2024-04-25 08:32:50   90735  \n",
      "50  289699059  599336832 2024-04-25 08:34:57   WYSSG  \n",
      "69  289699092  599368271 2024-04-25 09:35:40  104044  \n",
      "77  289699020  599352368 2024-04-25 08:58:32  157242  \n",
      "83  289698989  599596447 2024-04-25 16:43:36  177601  \n",
      "94  289699021  599348292 2024-04-25 08:43:44  147365  \n",
      "96  289699106  599349216 2024-04-25 08:47:15   18169  \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ? maybe remove _ check for NaN / missing values in DF",
   "id": "7e6bf76d9b261fe1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:32:45.378311Z",
     "start_time": "2024-12-27T22:32:44.724812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for null values\n",
    "# Total count of missing values in the DataFrame\n",
    "total_missing = df_bewegungen.isnull().sum().sum()\n",
    "print(f\"Total missing values in the DataFrame: {total_missing}\")\n",
    "\n",
    "# Filter DataFrame to show only rows with at least one missing value\n",
    "rows_with_missing_values = df_bewegungen[df_bewegungen.isnull().any(axis=1)]\n",
    "\n",
    "# Display the rows with missing values\n",
    "print(rows_with_missing_values)"
   ],
   "id": "a2ee7af9e21f8e96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in the DataFrame: 0\n",
      "Empty DataFrame\n",
      "Columns: [SRC_ITEM, SRC_LOT, DST_QACODE, SRC_X, SRC_Y, SRC_Z, OUTNUM, LISNUM, SUMLIS, TRNNUM, TRNDAT, USERID]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# WA kopf.csv prep",
   "id": "d3c1bdce32eb89b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:12:22.141279Z",
     "start_time": "2024-12-28T11:11:36.156767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Consolidated:::\n",
    "# List of columns to keep (ran into memory issues...)\n",
    "columns_to_keep = [\n",
    "    \"OUTNUM\", \"DOCNUM\", \"STATUS\", \"PICCOD\", \"CUSNUM\",\n",
    "    \"SHPTYP\", \"TOUR\", # \"TRNDAT\" \"CRTDAT\", \"ORDDAT\", \"DLVDAT\", not needed rn\n",
    "]\n",
    "\n",
    "dtypes = {\n",
    "    \"OUTNUM\": \"int32\", # KEY\n",
    "    \"DOCNUM\": \"category\", # Warenausgangsnummer\n",
    "    # \"ORDNUM\": \"category\", # dont think i need this, seems it achieves the same as DOCNUM\n",
    "    \"STATUS\": \"int32\",\n",
    "    \"PICCOD\": \"category\",\n",
    "    \"CUSNUM\": \"category\", # kunde\n",
    "    \"SHPTYP\": \"category\", # versandart\n",
    "    \"TOUR\": \"category\",\n",
    "}\n",
    "\n",
    "df_wa_kopf = pd.read_csv(\n",
    "    '../Data/wa_kopf.csv',\n",
    "    usecols=columns_to_keep,  # Only load the specified columns\n",
    "    dtype=dtypes,\n",
    "    #usecols=columns_to_use,  # Only load required columns\n",
    "    #dtype=dtypes,            # Use optimized data types\n",
    "    # parse_dates=[\"TRNDAT\"], # \"ORDDAT\", \"DLVDAT\", \"CRTDAT\",  not needed rn\n",
    "    low_memory=False\n",
    ")\n",
    "# Filter the DataFrame to keep only rows with status == 90 (abgeschlossene)\n",
    "df_wa_kopf = df_wa_kopf[df_wa_kopf['STATUS'] == 90]\n",
    "\n",
    "# Drop rows with missing values from the DataFrame - some early data and regression tests lead to PICCOD, SHPTYP and TOUR being empty (~86 rows)\n",
    "df_wa_kopf.dropna(inplace=True) # inplace=True modifies DataFrame directly without having to create a new one\n",
    "\n",
    "# Drop both 'SRC_WA' and 'DST_WA' columns from the DataFrame now that we filtered the data\n",
    "df_wa_kopf.drop(columns=['STATUS'], inplace=True)\n",
    "\n",
    "# Step 1: Merge main DataFrame with customers\n",
    "# df_orders = pd.merge(df_bewegungen, df_wa_kopf, on='OUTNUM', how='inner')\n",
    "\n",
    "#:::"
   ],
   "id": "aeff0654c5b44462",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T14:27:00.296263Z",
     "start_time": "2024-12-29T14:26:59.045225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract unique values from both columns\n",
    "unique_col_table1 = df_bewegungen['OUTNUM'].unique()\n",
    "unique_col_table2 = df_wa_kopf['OUTNUM'].unique()\n",
    "\n",
    "# Compare unique sets\n",
    "print(f\"Number of unique values in table1: {len(unique_col_table1)}\")\n",
    "print(f\"Number of unique values in table2: {len(unique_col_table2)}\")"
   ],
   "id": "99ea998ef7da3b8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in table1: 17599585\n",
      "Number of unique values in table2: 19314904\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T14:27:49.843835Z",
     "start_time": "2024-12-29T14:27:48.714107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count duplicate values in the OUTNUM column\n",
    "num_duplicates = df_wa_kopf['OUTNUM'].duplicated().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of duplicate values in the OUTNUM column: {num_duplicates}\")\n",
    "# Filter rows with duplicate values in the OUTNUM column\n",
    "duplicate_rows = df_wa_kopf[df_wa_kopf['OUTNUM'].duplicated(keep=False)]\n",
    "\n",
    "# Retrieve the first 10 rows with duplicates\n",
    "top_10_duplicates = duplicate_rows.head(10)\n",
    "\n",
    "# Print the first 10 duplicate rows\n",
    "print(\"First 10 rows with duplicate values in the OUTNUM column:\")\n",
    "print(top_10_duplicates)"
   ],
   "id": "315f7185464ed509",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate values in the OUTNUM column: 0\n",
      "First 10 rows with duplicate values in the OUTNUM column:\n",
      "Empty DataFrame\n",
      "Columns: [OUTNUM, DOCNUM, STATUS, PICCOD, CUSNUM, SHPTYP, TOUR]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:32:53.775Z",
     "start_time": "2024-12-27T22:32:53.351204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for null values\n",
    "# Total count of missing values in the DataFrame\n",
    "total_missing = df_wa_kopf.isnull().sum().sum()\n",
    "print(f\"Total missing values in the DataFrame: {total_missing}\")\n",
    "\n",
    "# Filter DataFrame to show only rows with at least one missing value\n",
    "rows_with_missing_values = df_wa_kopf[df_wa_kopf.isnull().any(axis=1)]\n",
    "\n",
    "# Display the rows with missing values\n",
    "print(rows_with_missing_values)"
   ],
   "id": "243ea4cb85c57e28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in the DataFrame: 0\n",
      "Empty DataFrame\n",
      "Columns: [OUTNUM, DOCNUM, STATUS, PICCOD, CUSNUM, SHPTYP, TOUR]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T21:51:22.160077Z",
     "start_time": "2024-12-27T21:51:20.113910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in SRC_WA\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_wa_kopf['OUTNUM'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_wa_kopf['OUTNUM'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'OUTNUM' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)"
   ],
   "id": "39e57834bc2069c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19314904 unique entries in the 'OUTNUM' column.\n",
      "\n",
      "Occurrences of each unique entry:\n",
      "30723507    1\n",
      "31429611    1\n",
      "31418553    1\n",
      "31422515    1\n",
      "31418440    1\n",
      "           ..\n",
      "22136170    1\n",
      "22136169    1\n",
      "22136168    1\n",
      "22136167    1\n",
      "35224902    1\n",
      "Name: OUTNUM, Length: 19314904, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T21:51:48.150748Z",
     "start_time": "2024-12-27T21:51:41.277966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in SRC_WA\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_wa_kopf['DOCNUM'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_wa_kopf['DOCNUM'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'ORDNUM' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)"
   ],
   "id": "e444b52da219d317",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5965848 unique entries in the 'ORDNUM' column.\n",
      "\n",
      "Occurrences of each unique entry:\n",
      "28377289    5002\n",
      "28109999    3890\n",
      "28055543    3847\n",
      "28168002    3829\n",
      "28062966    3718\n",
      "            ... \n",
      "28592674       0\n",
      "28592676       0\n",
      "34653261       0\n",
      "34653258       0\n",
      "34656371       0\n",
      "Name: DOCNUM, Length: 5970945, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:56:39.062287Z",
     "start_time": "2024-12-27T22:56:36.674055Z"
    }
   },
   "cell_type": "code",
   "source": "df_wa_kopf.info()",
   "id": "1ac8566b1a70c00b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19314904 entries, 0 to 19377912\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Dtype   \n",
      "---  ------  -----   \n",
      " 0   OUTNUM  int32   \n",
      " 1   DOCNUM  category\n",
      " 2   STATUS  int32   \n",
      " 3   PICCOD  category\n",
      " 4   CUSNUM  category\n",
      " 5   SHPTYP  category\n",
      " 6   TOUR    category\n",
      "dtypes: category(5), int32(2)\n",
      "memory usage: 654.8 MB\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T14:14:10.583726Z",
     "start_time": "2024-12-29T14:14:10.573717Z"
    }
   },
   "cell_type": "code",
   "source": "df_wa_kopf.head()",
   "id": "49e9e5c3991b509b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     OUTNUM    DOCNUM  STATUS  PICCOD  CUSNUM SHPTYP TOUR\n",
       "0  30723507  33054472      90    BS17  100986     02   85\n",
       "1  30711706  33052260      90    BS17   94536     02   85\n",
       "2  30730649  33056533      90    BS17   90715     02   83\n",
       "3  30712103  33052611      90  BS15-S  165269    124   00\n",
       "4  30733401  33057203      90    BS17    2542     02   94"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUTNUM</th>\n",
       "      <th>DOCNUM</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>PICCOD</th>\n",
       "      <th>CUSNUM</th>\n",
       "      <th>SHPTYP</th>\n",
       "      <th>TOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30723507</td>\n",
       "      <td>33054472</td>\n",
       "      <td>90</td>\n",
       "      <td>BS17</td>\n",
       "      <td>100986</td>\n",
       "      <td>02</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30711706</td>\n",
       "      <td>33052260</td>\n",
       "      <td>90</td>\n",
       "      <td>BS17</td>\n",
       "      <td>94536</td>\n",
       "      <td>02</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30730649</td>\n",
       "      <td>33056533</td>\n",
       "      <td>90</td>\n",
       "      <td>BS17</td>\n",
       "      <td>90715</td>\n",
       "      <td>02</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30712103</td>\n",
       "      <td>33052611</td>\n",
       "      <td>90</td>\n",
       "      <td>BS15-S</td>\n",
       "      <td>165269</td>\n",
       "      <td>124</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30733401</td>\n",
       "      <td>33057203</td>\n",
       "      <td>90</td>\n",
       "      <td>BS17</td>\n",
       "      <td>2542</td>\n",
       "      <td>02</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    # WA Positionen prep",
   "id": "de563cba443df1db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:13:48.016177Z",
     "start_time": "2024-12-28T11:13:17.747017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Consolidated\n",
    "\n",
    "# List of columns to keep (ran into memory issues...)\n",
    "columns_to_keep = [\n",
    "    \"OUTNUM\", \"STATUS\", \"ITEM\", # \"LOT\",\n",
    "    \"ORDQTY\", \"CONQTY\", \"USERID\", \"TRNNUM\" #  \"TRNDAT\", \"CRTDAT\", not needed rn\n",
    "]\n",
    "\n",
    "dtypes = {\n",
    "    #\"OUTLIN\": \"int32\", -- not used, useless column\n",
    "    \"OUTNUM\": \"int32\",\n",
    "    \"STATUS\": \"int32\",\n",
    "    \"ITEM\": \"category\",\n",
    "#    \"LOT\": \"string\", # 3 character string, e.G: 001, 002, 006, 012 etc.\n",
    "    \"ORDQTY\": \"int32\",\n",
    "#    \"RELQTY\": \"int32\" # freigegebene Menge\n",
    "#    \"FNDQTY\": \"int32\" # reservierte Menge\n",
    "#    \"SHPQTY\": \"int32\" # versendete Menge\n",
    "    \"CONQTY\": \"float32\", # setting this to float for initial load, going to clean the dataframe and change it to int later\n",
    "    \"USERID\": \"category\",\n",
    "    \"TRNNUM\": \"int32\"\n",
    "}\n",
    "\n",
    "# Load the CSV with optimized settings, and only load necessary cols\n",
    "df_wa_positionen = pd.read_csv(\n",
    "    '../Data/wa_positionen.csv',\n",
    "    usecols=columns_to_keep,  # Only load the specified columns\n",
    "    dtype=dtypes,\n",
    "    #usecols=columns_to_use,  # Only load required columns\n",
    "    #dtype=dtypes,            # Use optimized data types\n",
    "    # parse_dates=[\"TRNDAT\",\"CRTDAT\"] # , not needed rn\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Drop rows with missing values from the DataFrame\n",
    "df_wa_positionen.dropna(inplace=True)\n",
    "\n",
    "# Drop rows where CONQTY has a fractional part (i.e., a value with anything after the decimal point)\n",
    "df_wa_positionen = df_wa_positionen[df_wa_positionen[\"CONQTY\"] % 1 == 0]\n",
    "\n",
    "# Convert CONQTY column to integer type to reflect that it no longer has fractions\n",
    "df_wa_positionen[\"CONQTY\"] = df_wa_positionen[\"CONQTY\"].astype(int)\n",
    "\n",
    "## WRITE TO CSV todo\n",
    "\n",
    "# :::"
   ],
   "id": "51ccd801a9f8c734",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:14:24.752455Z",
     "start_time": "2024-12-28T11:14:23.592952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count duplicate values in the OUTNUM column\n",
    "num_duplicates = df_wa_positionen['OUTNUM'].duplicated().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of duplicate values in the OUTNUM column: {num_duplicates}\")\n",
    "# Filter rows with duplicate values in the OUTNUM column\n",
    "duplicate_rows = df_wa_positionen[df_wa_positionen['OUTNUM'].duplicated(keep=False)]\n",
    "\n",
    "# Retrieve the first 10 rows with duplicates\n",
    "top_10_duplicates = duplicate_rows.head(10)\n",
    "\n",
    "# Print the first 10 duplicate rows\n",
    "print(\"First 10 rows with duplicate values in the OUTNUM column:\")\n",
    "print(top_10_duplicates)"
   ],
   "id": "86d4940c4fb30ec8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate values in the OUTNUM column: 1333\n",
      "First 10 rows with duplicate values in the OUTNUM column:\n",
      "          OUTNUM  STATUS      ITEM  ORDQTY  CONQTY  USERID     TRNNUM\n",
      "51897   15783851      90   4574463       7       7   LXONE  497154217\n",
      "51898   15783851      90   4574463       3       3   LXONE  497154217\n",
      "62476   15794462      90  32858191      55      55  RIEDER  498057928\n",
      "62477   15794462      90  32858191      54      54  RIEDER  498057928\n",
      "67517   15799594      90  35170676      31      31  RIEDER  502119803\n",
      "67518   15799594      90  35170676     269     269  RIEDER  502296482\n",
      "74785   15806895      90  37085455       3       3   LXONE  498338562\n",
      "74786   15806895      90  37085455       2       2   LXONE  498338562\n",
      "127804  15860126      90   5173272       1       1  170719  503609904\n",
      "127805  15860126      90   5173272       1       1  170719  503609904\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:15:33.134411Z",
     "start_time": "2024-12-28T11:15:32.622947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter rows with duplicate values in the OUTNUM column\n",
    "duplicate_rows = df_wa_positionen[df_wa_positionen['OUTNUM'].duplicated(keep=False)]\n",
    "\n",
    "# Count the total number of rows that have duplicates\n",
    "num_duplicate_rows = len(duplicate_rows)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Total number of rows with duplicate values in the OUTNUM column: {num_duplicate_rows}\")"
   ],
   "id": "37bd217406964fb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows with duplicate values in the OUTNUM column: 2656\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:56:11.513882Z",
     "start_time": "2024-12-27T22:56:11.499678Z"
    }
   },
   "cell_type": "code",
   "source": "df_wa_positionen.info()",
   "id": "3c31d9655ba6ba1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19375221 entries, 0 to 19375223\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Dtype   \n",
      "---  ------  -----   \n",
      " 0   OUTNUM  int32   \n",
      " 1   STATUS  int32   \n",
      " 2   ITEM    category\n",
      " 3   LOT     string  \n",
      " 4   ORDQTY  int32   \n",
      " 5   CONQTY  int32   \n",
      " 6   USERID  category\n",
      " 7   TRNNUM  int32   \n",
      "dtypes: category(2), int32(5), string(1)\n",
      "memory usage: 815.2 MB\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T14:15:31.239284Z",
     "start_time": "2024-12-29T14:15:31.227274Z"
    }
   },
   "cell_type": "code",
   "source": "df_wa_positionen.head()",
   "id": "3cbb1d6e9f605452",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     OUTNUM  STATUS      ITEM  ORDQTY  CONQTY      USERID     TRNNUM\n",
       "0   9684339      90   4299149      11       7  PASAMONTES  536001122\n",
       "1  10756704      90  28872808      83      83      168388  807604606\n",
       "2  10756724      90  19020166      40      40      168388  807604231\n",
       "3  11244298      90  35282807       3       3      MUAMET  518249888\n",
       "4  11244340      90  35448829       4       4      MUAMET  518249888"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUTNUM</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ITEM</th>\n",
       "      <th>ORDQTY</th>\n",
       "      <th>CONQTY</th>\n",
       "      <th>USERID</th>\n",
       "      <th>TRNNUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9684339</td>\n",
       "      <td>90</td>\n",
       "      <td>4299149</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>PASAMONTES</td>\n",
       "      <td>536001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10756704</td>\n",
       "      <td>90</td>\n",
       "      <td>28872808</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>168388</td>\n",
       "      <td>807604606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10756724</td>\n",
       "      <td>90</td>\n",
       "      <td>19020166</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>168388</td>\n",
       "      <td>807604231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11244298</td>\n",
       "      <td>90</td>\n",
       "      <td>35282807</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>MUAMET</td>\n",
       "      <td>518249888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11244340</td>\n",
       "      <td>90</td>\n",
       "      <td>35448829</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>MUAMET</td>\n",
       "      <td>518249888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:33:48.428852Z",
     "start_time": "2024-12-27T22:33:46.757385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for null values\n",
    "# Total count of missing values in the DataFrame\n",
    "total_missing = df_wa_positionen.isnull().sum().sum()\n",
    "print(f\"Total missing values in the DataFrame: {total_missing}\")\n",
    "\n",
    "# Filter DataFrame to show only rows with at least one missing value\n",
    "rows_with_missing_values = df_wa_positionen[df_wa_positionen.isnull().any(axis=1)]\n",
    "\n",
    "# Display the rows with missing values\n",
    "print(rows_with_missing_values)"
   ],
   "id": "3d13a14c20c51893",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in the DataFrame: 0\n",
      "Empty DataFrame\n",
      "Columns: [OUTNUM, STATUS, ITEM, LOT, ORDQTY, CONQTY, USERID, TRNNUM]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:33:57.809520Z",
     "start_time": "2024-12-27T22:33:56.596321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in SRC_QACODE\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_wa_positionen['LOT'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_wa_positionen['LOT'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'SRC_QACODE' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)"
   ],
   "id": "3469659e165c1b6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 80 unique entries in the 'SRC_QACODE' column.\n",
      "\n",
      "Occurrences of each unique entry:\n",
      "001      15432416\n",
      "000       2097906\n",
      "002        717644\n",
      "003        346643\n",
      "004        215649\n",
      "           ...   \n",
      "0016            5\n",
      "1001            2\n",
      "223             1\n",
      ".001            1\n",
      "de001           1\n",
      "Name: LOT, Length: 80, dtype: Int64\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:52:03.663317Z",
     "start_time": "2024-12-27T17:52:02.015758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for null values\n",
    "# Total count of missing values in the DataFrame\n",
    "total_missing = df_wa_positionen.isnull().sum().sum()\n",
    "print(f\"Total missing values in the DataFrame: {total_missing}\")\n",
    "\n",
    "# Filter DataFrame to show only rows with at least one missing value\n",
    "rows_with_missing_values = df_wa_positionen[df_wa_positionen.isnull().any(axis=1)]\n",
    "\n",
    "# Display the rows with missing values\n",
    "print(rows_with_missing_values)"
   ],
   "id": "61001d33cc0378f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in the DataFrame: 0\n",
      "Empty DataFrame\n",
      "Columns: [OUTNUM, STATUS, ITEM, LOT, ORDQTY, CONQTY, USERID, TRNNUM]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:53:10.318779Z",
     "start_time": "2024-12-27T17:53:10.204676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter rows where CONQTY contains an actual float value\n",
    "float_rows = df_wa_positionen[df_wa_positionen[\"CONQTY\"] % 1 != 0]\n",
    "\n",
    "# Display the rows with float values in CONQTY\n",
    "print(\"Rows with actual float values in the CONQTY column:\")\n",
    "print(float_rows)"
   ],
   "id": "a3dba9ccea042401",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with actual float values in the CONQTY column:\n",
      "Empty DataFrame\n",
      "Columns: [OUTNUM, STATUS, ITEM, LOT, ORDQTY, CONQTY, USERID, TRNNUM]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:53:16.431652Z",
     "start_time": "2024-12-27T17:53:16.423645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count_float_values = len(float_rows)\n",
    "print(f\"Number of rows with float values in CONQTY: {count_float_values}\")"
   ],
   "id": "d20991fd66a8ddb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with float values in CONQTY: 0\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Joins",
   "id": "6260fb5bf5fd1d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T23:11:17.843140Z",
     "start_time": "2024-12-27T23:11:01.579741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Group and count OUTNUM in the original tables\n",
    "bewegungen_counts = df_bewegungen.groupby('OUTNUM').size()\n",
    "kopf_counts = df_wa_kopf.groupby('OUTNUM').size()\n",
    "positionen_counts = df_wa_positionen.groupby('OUTNUM').size()\n",
    "\n",
    "# Combine the counts into a comparison DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'Bewegungen': bewegungen_counts,\n",
    "    'Kopf': kopf_counts,\n",
    "    'Positionen': positionen_counts\n",
    "}).fillna(0)  # Fill missing values with 0\n",
    "\n",
    "# Add a total column\n",
    "summary_df['Total Matches'] = summary_df.sum(axis=1)\n",
    "\n",
    "# Filter keys with one-to-many relationships\n",
    "one_to_many_keys = summary_df[(summary_df['Kopf'] > 1) | (summary_df['Positionen'] > 1)]\n",
    "print(one_to_many_keys)"
   ],
   "id": "3fba5de596066fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Bewegungen  Kopf  Positionen  Total Matches\n",
      "OUTNUM                                               \n",
      "15783851         3.0   1.0         2.0            6.0\n",
      "15794462         6.0   1.0         2.0            9.0\n",
      "15799594        11.0   1.0         2.0           14.0\n",
      "15806895         3.0   1.0         2.0            6.0\n",
      "15860126         2.0   1.0         2.0            5.0\n",
      "...              ...   ...         ...            ...\n",
      "35093408         2.0   1.0         2.0            5.0\n",
      "35098455         2.0   1.0         2.0            5.0\n",
      "35110153         2.0   1.0         2.0            5.0\n",
      "35169793         2.0   1.0         2.0            5.0\n",
      "35215210         3.0   1.0         2.0            6.0\n",
      "\n",
      "[1323 rows x 4 columns]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T23:12:54.959360Z",
     "start_time": "2024-12-27T23:12:51.270717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Group by OUTNUM in the final DataFrame and count rows\n",
    "final_counts = df_full.groupby('OUTNUM').size()\n",
    "\n",
    "# Filter for keys with more than one match in df_full\n",
    "one_to_many_final = final_counts[final_counts > 1]\n",
    "\n",
    "# Display the results\n",
    "print(f\"Keys with one-to-many relationships after the join:\")\n",
    "print(one_to_many_final)"
   ],
   "id": "b6f5ec8ce74eeaa0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys with one-to-many relationships after the join:\n",
      "OUTNUM\n",
      "15427705    2\n",
      "15427706    2\n",
      "15427707    2\n",
      "15427708    2\n",
      "15427709    2\n",
      "           ..\n",
      "35244232    2\n",
      "35244237    5\n",
      "35244246    2\n",
      "35245563    2\n",
      "35246048    2\n",
      "Length: 205664, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# = pd.merge(df_bewegungen, df_wa_kopf, on='OUTNUM', how='inner')\n"
   ],
   "id": "810e35cc4cb03fbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:23:10.731668Z",
     "start_time": "2024-12-28T11:22:55.247321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_full = (\n",
    "    pd.merge(df_bewegungen, df_wa_kopf, on='OUTNUM', how='inner')\n",
    "    .merge(df_wa_positionen, on='OUTNUM', how='inner')\n",
    ")\n",
    "\n",
    "print(df_full.head())\n"
   ],
   "id": "d81963a2ec8a920d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SRC_ITEM SRC_LOT DST_QACODE SRC_X SRC_Y SRC_Z    OUTNUM     LISNUM  \\\n",
      "0  36529803     001          H  1601    02   D15  31313376  289679194   \n",
      "1  44118619     001          H  1780    02   E03  31320349  289874022   \n",
      "2  13091411     001          H  2215    04   F13  31324968  289835037   \n",
      "3  16359571     001          H  2004    07   G05  31346782  289840157   \n",
      "4  38789620     001          H  0112    08  BA05  31344732  289808077   \n",
      "\n",
      "      SUMLIS   TRNNUM_x  ...      PICCOD  CUSNUM SHPTYP  TOUR STATUS_y  \\\n",
      "0  289679311  599324284  ...     BS17-Do   83055     02    93       90   \n",
      "1  289874463  599670338  ...        BS17  164073     02    95       90   \n",
      "2  289835121  599596179  ...  BS15-Di/Do   34858     07    52       90   \n",
      "3  289725531  599576127  ...        BS17   30804     02    96       90   \n",
      "4  289726826  599529006  ...        BS17   13105     07    59       90   \n",
      "\n",
      "       ITEM ORDQTY CONQTY  USERID_y   TRNNUM_y  \n",
      "0  36529803      9      9     LXONE  599670642  \n",
      "1  44118619      2      2     LXONE  599678660  \n",
      "2  13091411      1      1     LXONE  599659813  \n",
      "3  16359571      1      1     LXONE  599659634  \n",
      "4  38789620      1      1     LXONE  599652028  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T23:06:19.359088Z",
     "start_time": "2024-12-27T23:06:18.190977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count occurrences of OUTNUM in the joined DataFrame\n",
    "outnum_counts = df_full['OUTNUM'].value_counts()\n",
    "\n",
    "# Display the distribution\n",
    "print(outnum_counts)\n",
    "\n",
    "# Check for entries with more than one match\n",
    "one_to_many = outnum_counts[outnum_counts > 1]\n",
    "print(f\"Number of one-to-many relationships: {len(one_to_many)}\")\n",
    "print(one_to_many)"
   ],
   "id": "b5739901b1706111",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17514071    50\n",
      "26680720    46\n",
      "22799765    40\n",
      "34917870    40\n",
      "19772684    39\n",
      "            ..\n",
      "21956928     1\n",
      "21940998     1\n",
      "21941002     1\n",
      "21944954     1\n",
      "35092650     1\n",
      "Name: OUTNUM, Length: 17194390, dtype: int64\n",
      "Number of one-to-many relationships: 205664\n",
      "17514071    50\n",
      "26680720    46\n",
      "22799765    40\n",
      "34917870    40\n",
      "19772684    39\n",
      "            ..\n",
      "24868779     2\n",
      "32000063     2\n",
      "28362691     2\n",
      "17381903     2\n",
      "24604344     2\n",
      "Name: OUTNUM, Length: 205664, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T12:41:42.522751Z",
     "start_time": "2024-12-29T12:40:54.417921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find duplicates in the entire DataFrame\n",
    "duplicates = df_full[df_full.duplicated()]\n",
    "\n",
    "# Print duplicates (if any exist)\n",
    "print(duplicates)\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "print(f\"Number of duplicate rows: {len(duplicates)}\")"
   ],
   "id": "11c725c5a4920c01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          SRC_ITEM SRC_LOT DST_QACODE SRC_X SRC_Y SRC_Z    OUTNUM     LISNUM  \\\n",
      "83895     25406197     003          H  0924    08   A02  31339265  289880687   \n",
      "83897     25406197     004          H  0919    05   F02  31339265  289880687   \n",
      "89052     35536664     002          H  1516    04   F04  30314877  280195471   \n",
      "89054     35536664     001          H  1511    03   E02  30314877  280195468   \n",
      "89056     35536664     002          H  1780    03   D02  30314877  280195481   \n",
      "...            ...     ...        ...   ...   ...   ...       ...        ...   \n",
      "17341329  38369989     002          H  1204    02   E04  35110153  327008835   \n",
      "17341331  38369989     003          H  0703    07   G04  35110153  327008385   \n",
      "17367746  45670606     004          H  0208    03   B02  34786997  323805694   \n",
      "17493352  30885830     005          H  1007    08   C01  35098455  326878694   \n",
      "17493354  30885830     004          H  0608    07   D01  35098455  326878589   \n",
      "\n",
      "             SUMLIS   TRNNUM_x  ...      PICCOD  CUSNUM SHPTYP  TOUR STATUS_y  \\\n",
      "83895     289881209  601260423  ...        BS17  174427     18    00       90   \n",
      "83897     289881209  601260330  ...        BS17  174427     18    00       90   \n",
      "89052     280195620  521710238  ...  BS17ohneFr   10529     18    00       90   \n",
      "89054     280195533  521723125  ...  BS17ohneFr   10529     18    00       90   \n",
      "89056     280195621  521712341  ...  BS17ohneFr   10529     18    00       90   \n",
      "...             ...        ...  ...         ...     ...    ...   ...      ...   \n",
      "17341329  327010460  995503157  ...        BS17    1286     07    54       90   \n",
      "17341331  327010460  995463812  ...        BS17    1286     07    54       90   \n",
      "17367746  323805871  963347970  ...        BS17   98057     02    85       90   \n",
      "17493352  326878959  991086189  ...        BS17  133232     02    95       90   \n",
      "17493354  326878959  991071242  ...        BS17  133232     02    95       90   \n",
      "\n",
      "              ITEM ORDQTY CONQTY  USERID_y   TRNNUM_y  \n",
      "83895     25406197      4      4    175847  606874935  \n",
      "83897     25406197      4      4    175847  606874935  \n",
      "89052     35536664     15     15    171995  537178761  \n",
      "89054     35536664     15     15    171995  537178761  \n",
      "89056     35536664     15     15    171995  537178761  \n",
      "...            ...    ...    ...       ...        ...  \n",
      "17341329  38369989     10     10     LXONE  995841495  \n",
      "17341331  38369989     10     10     LXONE  995841495  \n",
      "17367746  45670606      1      0  CHRISTEN  982507244  \n",
      "17493352  30885830      2      2     LXONE  991116900  \n",
      "17493354  30885830      2      2     LXONE  991116900  \n",
      "\n",
      "[1548 rows x 24 columns]\n",
      "Number of duplicate rows: 1548\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:55:20.940700Z",
     "start_time": "2024-12-27T22:55:18.108621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find duplicates based on specific columns, e.g., OUTNUM\n",
    "duplicates = df_full[df_full.duplicated(subset=['OUTNUM'])]\n",
    "\n",
    "# Print the duplicate rows\n",
    "print(duplicates)\n",
    "\n",
    "# Count duplicate rows based on OUTNUM\n",
    "print(f\"Number of duplicate rows based on OUTNUM: {len(duplicates)}\")"
   ],
   "id": "81adf57e2574c0c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          SRC_ITEM SRC_LOT DST_QACODE SRC_X SRC_Y SRC_Z    OUTNUM     LISNUM  \\\n",
      "24        44492423     001          H  0212    08   D03  31343207  289724989   \n",
      "25        44492423     001          H  1780    05   C01  31343207  289789886   \n",
      "32        38577015     001          H  1418    10   C10  31269284  289698921   \n",
      "33        38577015     001          H  1207    10   H03  31269284  289698887   \n",
      "34        38577015     001          H  0603    13   B15  31269284  289698844   \n",
      "...            ...     ...        ...   ...   ...   ...       ...        ...   \n",
      "17498788   1019832     006          H  1916    08   D01  35079291  326705790   \n",
      "17499754  33957262     001          H  2002    02   B04  35091016  326789913   \n",
      "17500949  46576644     001          H  2605    98   A01  35087506  326754964   \n",
      "17502099  36538297     001          H  1207    02   C03  35096533  326847082   \n",
      "17504440  45496856     001          H  2245    04   B01  35094269  326825209   \n",
      "\n",
      "             SUMLIS   TRNNUM_x  ...  CUSNUM SHPTYP    TOUR  STATUS_y  \\\n",
      "24        289696877  599501467  ...   44365     02      86        90   \n",
      "25        289789898  599559055  ...   44365     02      86        90   \n",
      "32        289699004  599360598  ...    6850    004  264966        90   \n",
      "33        289699062  599541942  ...    6850    004  264966        90   \n",
      "34        289698979  599315354  ...    6850    004  264966        90   \n",
      "...             ...        ...  ...     ...    ...     ...       ...   \n",
      "17498788  326705845  990518898  ...  156905     02      83        90   \n",
      "17499754  326784857  990701904  ...    1604     07      52        90   \n",
      "17500949  326754968  990585893  ...   17561     04      00        90   \n",
      "17502099  326784733  991023209  ...  165224     02      84        90   \n",
      "17504440  326825225  990746408  ...   92995     02      95        90   \n",
      "\n",
      "              ITEM  LOT ORDQTY CONQTY  USERID_y   TRNNUM_y  \n",
      "24        44492423  001      3      3    165925  599686758  \n",
      "25        44492423  001      3      3    165925  599686758  \n",
      "32        38577015  001     28     28     LXONE  599648517  \n",
      "33        38577015  001     28     28     LXONE  599648517  \n",
      "34        38577015  001     28     28     LXONE  599648517  \n",
      "...            ...  ...    ...    ...       ...        ...  \n",
      "17498788   1019832  006     21     21     LXONE  990873164  \n",
      "17499754  33957262  001     18     18     LXONE  990734140  \n",
      "17500949  46576644  001     50     50    178097  990615218  \n",
      "17502099  36538297  001      3      3     LXONE  991042785  \n",
      "17504440  45496856  001      5      5     LXONE  991121132  \n",
      "\n",
      "[311240 rows x 25 columns]\n",
      "Number of duplicate rows based on OUTNUM: 311240\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:52:52.172139Z",
     "start_time": "2024-12-27T22:52:02.264371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if all rows are unique\n",
    "is_unique = not df_full.duplicated().any()\n",
    "\n",
    "# Print result\n",
    "if is_unique:\n",
    "    print(\"All rows in df_full are unique.\")\n",
    "else:\n",
    "    print(\"There are duplicate rows in df_full.\")"
   ],
   "id": "926e2954f5e46058",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are duplicate rows in df_full.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T22:54:52.494811Z",
     "start_time": "2024-12-27T22:54:03.309375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count the number of duplicate rows in the DataFrame\n",
    "num_duplicates = df_full.duplicated().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of duplicate rows in df_full: {num_duplicates}\")"
   ],
   "id": "47a6bc9d26b03271",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows in df_full: 1325\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:38:59.343488Z",
     "start_time": "2024-12-28T11:38:56.826424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_full.head()\n",
    "df_full.info()"
   ],
   "id": "18957fb0431e8f8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17505630 entries, 0 to 17505629\n",
      "Data columns (total 24 columns):\n",
      " #   Column      Dtype         \n",
      "---  ------      -----         \n",
      " 0   SRC_ITEM    category      \n",
      " 1   SRC_LOT     category      \n",
      " 2   DST_QACODE  category      \n",
      " 3   SRC_X       category      \n",
      " 4   SRC_Y       category      \n",
      " 5   SRC_Z       category      \n",
      " 6   OUTNUM      int32         \n",
      " 7   LISNUM      int32         \n",
      " 8   SUMLIS      int32         \n",
      " 9   TRNNUM_x    int32         \n",
      " 10  TRNDAT      datetime64[ns]\n",
      " 11  USERID_x    category      \n",
      " 12  DOCNUM      category      \n",
      " 13  STATUS_x    int32         \n",
      " 14  PICCOD      category      \n",
      " 15  CUSNUM      category      \n",
      " 16  SHPTYP      category      \n",
      " 17  TOUR        category      \n",
      " 18  STATUS_y    int32         \n",
      " 19  ITEM        category      \n",
      " 20  ORDQTY      int32         \n",
      " 21  CONQTY      int32         \n",
      " 22  USERID_y    category      \n",
      " 23  TRNNUM_y    int32         \n",
      "dtypes: category(14), datetime64[ns](1), int32(9)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:38:52.776393Z",
     "start_time": "2024-12-28T11:38:52.748368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####\n",
    "#### Cleaning - unique entries in SRC_QACODE\n",
    "####\n",
    "# Count the number of unique entries in the 'SRC_WA' column\n",
    "unique_entries_count = df_full['LOT'].nunique()\n",
    "\n",
    "# Count the occurrences of each unique entry in the 'SRC_WA' column\n",
    "unique_entries_occurrences = df_full['LOT'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {unique_entries_count} unique entries in the 'SRC_QACODE' column.\")\n",
    "print(\"\\nOccurrences of each unique entry:\")\n",
    "print(unique_entries_occurrences)"
   ],
   "id": "e16740ff8a114f0e",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LOT'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3360\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3361\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'LOT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_12112\\1824403216.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m####\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# Count the number of unique entries in the 'SRC_WA' column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0munique_entries_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_full\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'LOT'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnunique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# Count the occurrences of each unique entry in the 'SRC_WA' column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3456\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3457\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3458\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3459\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3460\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\Projects\\PyCharmProjects\\HS2024_MachineLearning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3361\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3363\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3364\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3365\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'LOT'"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:11:25.809679Z",
     "start_time": "2024-12-29T17:11:25.798669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_rows = len(df_full)\n",
    "print(f\"Number of rows: {num_rows}\")"
   ],
   "id": "fd6c62a2759ea196",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 17505630\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T14:34:03.077301Z",
     "start_time": "2024-12-26T14:33:58.610689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for null values\n",
    "# Total count of missing values in the DataFrame\n",
    "total_missing = df_full.isnull().sum().sum()\n",
    "print(f\"Total missing values in the DataFrame: {total_missing}\")\n",
    "\n",
    "# Filter DataFrame to show only rows with at least one missing value\n",
    "rows_with_missing_values = df_full[df_full.isnull().any(axis=1)]\n",
    "\n",
    "# Display the rows with missing values\n",
    "print(rows_with_missing_values)"
   ],
   "id": "28637ed8ef7e0298",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in the DataFrame: 0\n",
      "Empty DataFrame\n",
      "Columns: [WORNUM, STATUS_x, SRC_ITEM, SRC_LOT, SRC_QACODE, DST_LOT, DST_QACODE, SRC_WA, SRC_X, SRC_Y, SRC_Z, DST_WA, OUTNUM, LISNUM, SUMLIS, TRNNUM_x, CRTDAT_x, TRNDAT_x, USERID_x, DOCNUM, STATUS_y, PICCOD, CUSNUM, ORDDAT, DLVDAT, SHPTYP, TOUR, CRTDAT_y, TRNDAT_y, STATUS, ITEM, LOT, ORDQTY, CONQTY, CRTDAT, TRNDAT, USERID_y, TRNNUM_y]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 38 columns]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Export Dataframe to Parquet file",
   "id": "13c626012ee82467"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:42:35.438096Z",
     "start_time": "2024-12-28T11:42:21.888045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyarrow\n",
    "\n",
    "# Save the fully joined DataFrame to a Parquet file for better performance\n",
    "output_file = 'joined_data_v3.parquet'\n",
    "df_full.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"Fully joined DataFrame saved to {output_file}\")"
   ],
   "id": "3f0a3f4ed86413ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully joined DataFrame saved to joined_data_v3.parquet\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# reading parquet file later\n",
    "\n",
    "df_loaded = pd.read_parquet('joined_data.parquet')\n",
    "print(df_loaded.head())\n"
   ],
   "id": "d51518b2e64392a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##TEMP\n",
   "id": "f55023219bdda426"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T21:56:19.403878Z",
     "start_time": "2024-12-27T21:56:19.376744Z"
    }
   },
   "cell_type": "code",
   "source": "df_full.head()",
   "id": "d980f5634eeda664",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      WORNUM  STATUS_x  SRC_ITEM SRC_LOT SRC_QACODE DST_LOT DST_QACODE SRC_WA  \\\n",
       "0  289678987        50  36529803       1          H       1          H     EG   \n",
       "1  289870561        50  44118619       1          H       1          H     EG   \n",
       "2  289833599        50  13091411       1          H       1          H     EG   \n",
       "3  289815259        50   9636829       0          H       0          H     EG   \n",
       "4  289839097        50  16359571       1          H       1          H     EG   \n",
       "\n",
       "  SRC_X SRC_Y  ...  CUSNUM SHPTYP  TOUR  STATUS      ITEM  LOT ORDQTY CONQTY  \\\n",
       "0  1601    02  ...   83055     02    93      90  36529803  001      9      9   \n",
       "1  1780    02  ...  164073     02    95      90  44118619  001      2      2   \n",
       "2  2215    04  ...   34858     07    52      90  13091411  001      1      1   \n",
       "3  2401    02  ...   94180     07    52      90   9636829  000      1      1   \n",
       "4  2004    07  ...   30804     02    96      90  16359571  001      1      1   \n",
       "\n",
       "  USERID_y   TRNNUM_y  \n",
       "0    LXONE  599670642  \n",
       "1    LXONE  599678660  \n",
       "2    LXONE  599659813  \n",
       "3    LXONE  599669523  \n",
       "4    LXONE  599659634  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORNUM</th>\n",
       "      <th>STATUS_x</th>\n",
       "      <th>SRC_ITEM</th>\n",
       "      <th>SRC_LOT</th>\n",
       "      <th>SRC_QACODE</th>\n",
       "      <th>DST_LOT</th>\n",
       "      <th>DST_QACODE</th>\n",
       "      <th>SRC_WA</th>\n",
       "      <th>SRC_X</th>\n",
       "      <th>SRC_Y</th>\n",
       "      <th>...</th>\n",
       "      <th>CUSNUM</th>\n",
       "      <th>SHPTYP</th>\n",
       "      <th>TOUR</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ITEM</th>\n",
       "      <th>LOT</th>\n",
       "      <th>ORDQTY</th>\n",
       "      <th>CONQTY</th>\n",
       "      <th>USERID_y</th>\n",
       "      <th>TRNNUM_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289678987</td>\n",
       "      <td>50</td>\n",
       "      <td>36529803</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>EG</td>\n",
       "      <td>1601</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>83055</td>\n",
       "      <td>02</td>\n",
       "      <td>93</td>\n",
       "      <td>90</td>\n",
       "      <td>36529803</td>\n",
       "      <td>001</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>LXONE</td>\n",
       "      <td>599670642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289870561</td>\n",
       "      <td>50</td>\n",
       "      <td>44118619</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>EG</td>\n",
       "      <td>1780</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>164073</td>\n",
       "      <td>02</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>44118619</td>\n",
       "      <td>001</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>LXONE</td>\n",
       "      <td>599678660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289833599</td>\n",
       "      <td>50</td>\n",
       "      <td>13091411</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>EG</td>\n",
       "      <td>2215</td>\n",
       "      <td>04</td>\n",
       "      <td>...</td>\n",
       "      <td>34858</td>\n",
       "      <td>07</td>\n",
       "      <td>52</td>\n",
       "      <td>90</td>\n",
       "      <td>13091411</td>\n",
       "      <td>001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LXONE</td>\n",
       "      <td>599659813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289815259</td>\n",
       "      <td>50</td>\n",
       "      <td>9636829</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>EG</td>\n",
       "      <td>2401</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>94180</td>\n",
       "      <td>07</td>\n",
       "      <td>52</td>\n",
       "      <td>90</td>\n",
       "      <td>9636829</td>\n",
       "      <td>000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LXONE</td>\n",
       "      <td>599669523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289839097</td>\n",
       "      <td>50</td>\n",
       "      <td>16359571</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>EG</td>\n",
       "      <td>2004</td>\n",
       "      <td>07</td>\n",
       "      <td>...</td>\n",
       "      <td>30804</td>\n",
       "      <td>02</td>\n",
       "      <td>96</td>\n",
       "      <td>90</td>\n",
       "      <td>16359571</td>\n",
       "      <td>001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LXONE</td>\n",
       "      <td>599659634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:36:59.889307Z",
     "start_time": "2024-12-28T11:24:03.244577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Export df_full to a CSV file\n",
    "output_file = 'df_full_output.csv'  # Specify the file name\n",
    "df_full.to_csv(output_file, index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"DataFrame df_full has been successfully exported to {output_file}\")"
   ],
   "id": "7668aa12c636816b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_full has been successfully exported to df_full_output.csv\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Machine Learning\n",
   "id": "b168358213f6db00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:41:51.652614Z",
     "start_time": "2024-12-28T11:41:51.640603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encoding\n",
    "columns_and_types = df_full.dtypes.reset_index()\n",
    "columns_and_types.columns = ['Column', 'Data Type']\n",
    "\n",
    "# Display the table\n",
    "print(columns_and_types)"
   ],
   "id": "6e010e44af551a1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column       Data Type\n",
      "0     SRC_ITEM        category\n",
      "1      SRC_LOT        category\n",
      "2   DST_QACODE        category\n",
      "3        SRC_X        category\n",
      "4        SRC_Y        category\n",
      "5        SRC_Z        category\n",
      "6       OUTNUM           int32\n",
      "7       LISNUM           int32\n",
      "8       SUMLIS           int32\n",
      "9     TRNNUM_x           int32\n",
      "10      TRNDAT  datetime64[ns]\n",
      "11    USERID_x        category\n",
      "12      DOCNUM        category\n",
      "13    STATUS_x           int32\n",
      "14      PICCOD        category\n",
      "15      CUSNUM        category\n",
      "16      SHPTYP        category\n",
      "17        TOUR        category\n",
      "18    STATUS_y           int32\n",
      "19        ITEM        category\n",
      "20      ORDQTY           int32\n",
      "21      CONQTY           int32\n",
      "22    USERID_y        category\n",
      "23    TRNNUM_y           int32\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "240d2bfa06d3367f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
